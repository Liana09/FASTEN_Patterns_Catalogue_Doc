<?xml version = "1.0" encoding = "utf-8"?>
<html>
  <head>
    <meta charset="utf-8"></meta>
    <title>SafetyPatternsCatalogue</title>
    <style type="text/css">html{
font-family : sans-serif;
line-height : 120%;
}
a{
text-decoration : none;
}
.tableContainer{
}
.table{
}
.tablecaption{
}
table.inline{
}
table{
border-collapse : collapse;
}
td,th{
border : 1px solid grey;
padding : 0.5ex;
}
.tableOfContents{
}
.tocChapter{
margin-left : 2em;
}
.tocSection{
margin-left : 1em;
}
.section{
}
.codeblockContainer{
border : 2px solid grey;
padding : .5em;
overflow : auto;
margin : 1em 0;
}
.codeblock{
display : inline-block;
margin : 0;
}
.codeblock br{
display : none;
}
.originalNode::before{
content : "⬈";
display : inline-block;
padding-left : .1em;
}
.cref::after{
content : "⬈";
padding-left : .1em;
}
.greyBox{
background-color : lightgrey;
padding : 0.5em;
}
.imagecontainer{
margin : 1em 0;
}
.imagecontainer.border{
border : 2px solid grey;
padding : .5em;
}
img{
max-width : 100%;
}
.border .caption{
margin-bottom : 0;
padding-bottom : 0;
}
.imagecaption{
}
.caption{
font-size : 80%;
}
.bold{
}
.code{
}
.emph{
}
.keyPress{
-moz-border-radius : .5em;
-webkit-border-radius : .5em;
border-radius : .5em;
-moz-box-shadow : inset 0 1px 3px rgba(0, 0, 0, .7);
-webkit-box-shadow : inset 0 1px 3px rgba(0, 0, 0, .7);
box-shadow : inset 0 1px 3px rgba(0, 0, 0, .7);
background : rgb(240, 240, 240);
color : rgb(40, 40, 40);
display : inline;
display : inline-block;
padding : 0em .2em;
font-size : 80%;
}
.key{
display : inline;
display : inline-block;
min-width : 1em;
padding : .2em .3em;
margin : .2em;
font : normal .85em/1 "Lucida Grande", Lucida, Arial, sans-serif;
text-align : center;
text-decoration : none;
-moz-border-radius : .3em;
-webkit-border-radius : .3em;
border-radius : .3em;
border : none;
cursor : default;
-moz-user-select : none;
-webkit-user-select : none;
user-select : none;
}
.key{
background : rgb(80,80,80);
background : -moz-linear-gradient(top, rgb(60, 60, 60), rgb(80, 80, 80));
background : -webkit-gradient(linear, left top, left bottom, from(rgb(60, 60, 60)), to(rgb(80, 80, 80)));
color : rgb(250,250,250);
text-shadow : -1px -1px 0 rgb(70, 70, 70);
-moz-box-shadow : inset 0 0 1px rgb(150, 150, 150), inset 0 -.05em .4em rgb(80, 80, 80), 0 .1em 0 rgb(30, 30, 30), 0 .1em .1em rgba(0, 0, 0, .3);
-webkit-box-shadow : inset 0 0 1px rgb(150, 150, 150), inset 0 -.05em .4em rgb(80, 80, 80), 0 .1em 0 rgb(30, 30, 30), 0 .1em .1em rgba(0, 0, 0, .3);
box-shadow : inset 0 0 1px rgb(150, 150, 150), inset 0 -.05em .4em rgb(80, 80, 80), 0 .1em 0 rgb(30, 30, 30), 0 .1em .1em rgba(0, 0, 0, .3);
}
.math{
background-color : light-blue;
}
.menu{
background-color : green;
}
.menuClick{
-moz-box-shadow : inset 0 1px 3px rgba(0, 0, 0, .7);
-webkit-box-shadow : inset 0 1px 3px rgba(0, 0, 0, .7);
box-shadow : inset 0 1px 3px rgba(0, 0, 0, .7);
background : rgb(240, 240, 240);
color : rgb(40, 40, 40);
display : inline;
display : inline-block;
padding : 0em 0.2em;
font-size : 80%;
}
.menuItem{
display : inline;
display : inline-block;
min-width : 1em;
padding : .2em .3em;
margin : 0 .2em;
min-height : 1.2em;
font : normal .85em/1 "Lucida Grande", Lucida, Arial, sans-serif;
text-align : center;
text-decoration : none;
cursor : default;
-moz-user-select : none;
-webkit-user-select : none;
user-select : none;
background : rgb(0,0,240);
background : -moz-linear-gradient(top, rgb(0, 0, 220), rgb(0, 0, 240));
background : -webkit-gradient(linear, left top, left bottom, from(rgb(0, 0, 220)), to(rgb(0, 0, 240)));
color : rgb(250,250,250);
text-shadow : -1px -1px 0 rgb(70, 70, 70);
}
.url{
text-decoration : underline;
}
.attachment{
}
.footnoteOrigin{
}
.footnoteText{
border-top : 1px solid lightgrey;
padding-top : 4px;
font-size : 80%;
}
.footnoteText+.footnoteText{
border-top : 0;
}
.imgRef{
}
.sectRef{
}
.docRef{
}
.todo{
background-color : yellow;
}
.cref{
}
.superscript{
}
</style>
  </head>
  <body>
    <div>
      <h1 id="sid1173803721179804198" class="section">1 Safety Patterns Catalogue</h1>
      <p class="body">A catalogue of safety patterns.</p>
      <div>
        <h1 id="toc" class="tableOfContents">Table of Contents</h1>
        <div class="tocSection">
          <a href="#sid1173803721179804198">1 Safety Patterns Catalogue</a>
          <div class="tocSection">
            <a href="#sid3859986046039743221">1.1 Risk-Based Argument Patterns</a>
            <div class="tocChapter">
              <strong><a href="#sid2706928751926334768">1.1.1 ALARP (As-Low-As-Reasonably-Practicable) Safety Argument Pattern</a></strong>
            </div>
            <div class="tocChapter">
              <strong><a href="#sid4829234473223371083">1.1.2 Component Contributions to System Hazards</a></strong>
            </div>
            <div class="tocChapter">
              <strong><a href="#sid7893292664124646102">1.1.3 Fault Tree Evidence</a></strong>
            </div>
            <div class="tocChapter">
              <strong><a href="#sid3666423621007720724">1.1.4 Hazard Avoidance Pattern</a></strong>
            </div>
            <div class="tocChapter">
              <strong><a href="#sid7893292664124639090">1.1.5 Hazard Directed Integrity Level Argument</a></strong>
            </div>
          </div>
          <div class="tocSection">
            <a href="#sid3859986046039743616">1.2  Fault/Failure-Based Argument Patterns</a>
            <div class="tocChapter">
              <strong><a href="#sid2524223438958843133">1.2.1  Extended / Hierarchical Physical Decomposition Pattern</a></strong>
            </div>
            <div class="tocChapter">
              <strong><a href="#sid2524223438958840483">1.2.2 Fault Free Pattern</a></strong>
            </div>
            <div class="tocChapter">
              <strong><a href="#sid81587047679133879">1.2.3 Handling of Hardware/Other Component Failure Mode</a></strong>
            </div>
            <div class="tocChapter">
              <strong><a href="#sid81587047679136567">1.2.4 Handling of Software Failure Mode</a></strong>
            </div>
            <div class="tocChapter">
              <strong><a href="#sid6723039987465357955">1.2.5 Hazardous Software Failure Mode Decomposition</a></strong>
            </div>
            <div class="tocChapter">
              <strong><a href="#sid6723039987465359979">1.2.6 Software Argument Approach</a></strong>
            </div>
          </div>
          <div class="tocSection">
            <a href="#sid1173803721179809910">1.3 Verification-based Argument Patterns</a>
            <div class="tocChapter">
              <strong><a href="#sid2186533634773259659">1.3.1 Property Assurance using formal evidence</a></strong>
            </div>
          </div>
          <div class="tocSection">
            <a href="#sid1173803721179809924">1.4 Requirements-based Argument Patterns</a>
            <div class="tocChapter">
              <strong><a href="#sid2524223438958841587">1.4.1  Requirements Breakdown Pattern</a></strong>
            </div>
            <div class="tocChapter">
              <strong><a href="#sid942157498040132670">1.4.2 Refinement of G2:HLRSAT</a></strong>
            </div>
            <div class="tocChapter">
              <strong><a href="#sid942157498040132859">1.4.3 Refinement of G3:EOCSAT</a></strong>
            </div>
          </div>
          <div class="tocSection">
            <a href="#sid1173803721179809887">1.5 ML-specific Argument Patterns</a>
            <div class="tocChapter">
              <strong><a href="#sid6452540484739656540">1.5.1 ML Safety Assurance Scoping</a></strong>
            </div>
            <div class="tocChapter">
              <strong><a href="#sid3666423621007717891">1.5.2 ML Safety Requirements Assurance</a></strong>
            </div>
            <div class="tocChapter">
              <strong><a href="#sid3666423621007718360">1.5.3 Data Management</a></strong>
            </div>
            <div class="tocChapter">
              <strong><a href="#sid3666423621007718644">1.5.4 Model Learning</a></strong>
            </div>
            <div class="tocChapter">
              <strong><a href="#sid3666423621007719155">1.5.5 ML Verification pattern</a></strong>
            </div>
            <div class="tocChapter">
              <strong><a href="#sid3666423621007719661">1.5.6 ML Model Deployment Pattern</a></strong>
            </div>
          </div>
          <div class="tocSection">
            <a href="#sid1173803721179809940">1.6 DO-178C-Specific Argument Patterns</a>
            <div class="tocChapter">
              <strong><a href="#sid1941327365747442494">1.6.1 Beginning of primary argument for level D software</a></strong>
            </div>
          </div>
          <div class="tocSection">
            <a href="#sid3859986046039745643">1.7 Confidence Argument Patterns</a>
            <div class="tocChapter">
              <strong><a href="#sid2186533634770907594">1.7.1 Confidence argument structure for an asserted inference</a></strong>
            </div>
            <div class="tocChapter">
              <strong><a href="#sid2186533634770908135">1.7.2 Confidence argument structure for an asserted solution</a></strong>
            </div>
            <div class="tocChapter">
              <strong><a href="#sid2186533634773199179">1.7.3 Overall confidence argument</a></strong>
            </div>
          </div>
          <div class="tocSection">
            <a href="#sid1173803721179809901">1.8 Automotive-Specific Argument Patterns</a>
            <div class="tocChapter">
              <strong><a href="#sid2186533634773578105">1.8.1 High Level Vehicle Argument Pattern</a></strong>
            </div>
            <div class="tocChapter">
              <strong><a href="#sid2186533634773586251">1.8.2 Predefined Safety Requirements Argument Pattern</a></strong>
            </div>
            <div class="tocChapter">
              <strong><a href="#sid2186533634773586357">1.8.3 Risk Management Argument Pattern</a></strong>
            </div>
            <div class="tocChapter">
              <strong><a href="#sid2186533634773586463">1.8.4 Risk Mitigation Argument Pattern</a></strong>
            </div>
          </div>
        </div>
      </div>
      <div>
        <h2 id="sid3859986046039743221" class="section">1.1 Risk-Based Argument Patterns</h2>
        <div>
          <h3 id="sid2706928751926334768" class="section">1.1.1 ALARP (As-Low-As-Reasonably-Practicable) Safety Argument Pattern</h3>
          <div class="imagecontainer border" id="sid5866579837810788370">
            <div class="imageWithBorder">
              <img src="../img/SafetyPatternsCatalogue_ALARP.png" />
            </div>
            <div class="imagecaption">
              <p class="caption">
                <b>Figure
                1.1.1-A</b><a href="http://127.0.0.1:63320/node?ref=r%3Af484f3cb-b75d-4857-b03a-36f42bd7a5b9%28_100_Patterns%29%2F2486937191970109068" class="originalNode" title="open in MPS"></a>
              </p>
            </div>
          </div>
          <p class="body">
            <b>Problem and Solution</b>&nbsp;&nbsp;This pattern provides a framework for arguing that identified risks in a system have been sufficiently addressed in accordance with the ALARP principle.<br/>
This pattern was developed for two reasons:<br/>
• To argue compliance with the ALARP principle at the highest level when addressing system level hazards.<br/>
• To provide a more structured approach to presenting a ‘Hazard Avoidance’ argument (See Hazard Avoidance Pattern) by showing differing treatment of hazards according to their associated risk. @docu
          </p>
          <p class="body">
            <b>Context</b>&nbsp;&nbsp;This pattern is applicable in contexts where the ALARP principle is accepted as the device for reasoning about the relative importance of risks and the cost-effectiveness of risk reduction.<br/>
In order to apply this pattern it is necessary to have access to the following contextual information: <br/>
• C1: Identified System Hazards (See Participants section)<br/>
• C2, C3, C4: Definition of Intolerable / Tolerable / Negligible Risk (See Participants section)<br/>
These definitions are typically provided by the appropriate regulatory authority, standards or through investigations by safety engineers, including discussions with customers. <br/>
• C5: Definition of Disproportionate (See Participants section) 
          </p>
          <p class="body">
            <b>Participants &amp; Collaborations</b>&nbsp;&nbsp;The pattern contains the following <strong class="bold">participants</strong>:<br/>
<strong class="bold">
            Goal G1
            :</strong> Defines the overall objective of the pattern.<br/>
<strong class="bold">
            Goal G2
            , 
            Goal G3
            , 
            Goal G4
            : </strong>Defines targets for three classes of identified risks: negligible, tolerable, and intolerable.<br/>
<strong class="bold">
            Solution Sn1
            : </strong>Provided at this point to support the claim that no intolerable risks have (ever) been identified with the system.<br/>
<strong class="bold">
            Goal G6
            , 
            Goal G7
            , goal
            Goal G8
            : </strong>Claims either that hazard has been eliminated or associated risk reduced to a tolerable level and dealt with as a tolerable risk.<br/>
<strong class="bold">
            Goal G8
            : </strong>Defines ALARP target for each identified tolerable risk.<br/>
<strong class="bold">
            Goal G10
            , 
            Goal G11
            , goal
            Goal G12
            : </strong><br/>
Claims required to support ALARP target: <br/>
• Hazard only acceptable if positive benefit achieved<br/>
• Risk reduction measures have been taken up to the point where further measures would be disproportionate to benefit gained.<br/>
<strong class="bold">
            Goal G9
            : </strong>Claim for each remaining hazard that associated risk shown to be negligible.<br/>
<strong class="bold">
            Context C1
            : </strong>A context identifying all system hazards, including indication of associated risks (e.g. Risk Category from A, B, C, D).<br/>
<strong class="bold">
            Context C2
            , 
            Context C3
            , 
            Context C4
            : </strong>A workable definition of ‘intolerable’/ ’tolerable’/ ’negligible’ risks that can be used as a basis for selection from the list of hazards (e.g. Intolerable = Risk Category A, Tolerable = Risk Category B or C, Negligible = D).<br/>
<strong class="bold">
            Context C5
            : </strong>The ALARP principle relies on some understanding of when it is no longer cost-effective to spend further money on risk reduction. This element, a definition of cost-effectiveness, is therefore required.<br/>
<code class="code">Collaborations:</code><br/>
An important aspect of this pattern is that it divides and conquers the goal of hazard mitigation / elimination according to the level of risk associated with each hazard. There are three strands to the safety argument: one tackling intolerable risks, one tackling tolerable risk and one discounting negligible risks. To satisfactorily support the top-level goal (G1) it is important that these three strands address all identified risks. The definitions of tolerable, intolerable and negligible (C3, C2 and C4 respectively) should therefore be so defined to cover and classify the range of possible levels of risks. It should also be noted that the definitions of negligibility (C4) and disproportionate (C5) cannot be considered entirely independently. It would not make sense, for example, to force risk reduction to a level below that identified elsewhere as negligible.<br/>
As the goal structure shows, if the means of addressing a previously identified intolerable risk is to reduce it to a tolerable level, then the remaining risk must be tackled as for all tolerable risks. If the level of risk has been reduced to a negligible level, then the hazard must be tackled as a negligible risk.<br/>
It is important that the source of Identified System Hazards (C1) identifies the level of risk posed by a hazard in a way that permits sub-division into the classes of risk defined by C2, C3 and C4.
          </p>
          <p class="body">
            <b>Implementation</b>&nbsp;&nbsp;Implementation of this pattern involves first instantiating the contexts: 
            Context C1
            , 
            Context C2
            , 
            Context C3
            , 
            Context C4
            . In the context of the list of hazards referenced by 
            Context C1
            , the solutions to goals 
            Goal G2
            , 
            Goal G3
             and 
            Goal G4
            can be provided. If no tolerable risks were ever present in the system, then reference to the system hazard log (Sn1) is sufficient to support the claim 
            Goal G2
            . However, if any intolerable risks have been identified, it is necessary to claim (
            Goal G5
            ) that these have been resolved through complete elimination of the hazard (
            Goal G6
            ), or reduction to a tolerable (
            Goal G7
            , 
            Goal G8
            ) or negligible (
            Goal G9
            ) level.<br/>
For each tolerable risk identified an argument must be constructed (
            Goal G6
            , 
            Goal G10
            , 
            Goal G11
            , 
            Goal G12
            ) to demonstrate that it has been addressed in accordance with the ALARP principles. Measures taken in risk reduction must be stated in support of 
            Goal G11
            . Some evidence / argument of the non cost-effectiveness of further risk reduction measures must be supplied in support of 
            Goal G12
            , in accordance with the definition given by 
            Context C5
            .<br/>
Evidence of risk analysis (probably based upon consideration of probability of occurrence) is required in support of each claim of hazards posing negligible risk (
            Goal G9
            ).<br/>
<br/>
<strong class="bold">Possible Pitfalls</strong><br/>
• Not providing complete coverage of levels of risk through definitions 
            Context C2
            , 
            Context C3
            , 
            Context C4
             <br/>
• Expressing definitions
            Context C2
            , 
            Context C3
            , 
            Context C4
            in a way that is difficult to apply to the information provided by 
            Context C1
             (and vice versa)<br/>
• Not having a commonly agreed concept of when to stop attempting further risk reduction (
            Context C1
            ) - this can result in a non- uniform approach to tackling risks where significantly different levels of effort are committed to risks at the same level.
          </p>
          <p class="body">
            <b>Related patterns &amp; Known Uses</b>&nbsp;&nbsp;Safe By Hazard Mitigation Argument<br/>
<code class="code">PAttern and documentation taken from: Kelly, Tim. (2001). Arguing Safety -- A Systematic Approach to Managing Safety Cases Timothy Patrick Kelly. </code>  
          </p>
        </div>
        <div>
          <h3 id="sid4829234473223371083" class="section">1.1.2 Component Contributions to System Hazards</h3>
          <div class="imagecontainer border" id="sid5866579837810789476">
            <div class="imageWithBorder">
              <img src="../img/SafetyPatternsCatalogue_Component_Contributions_to_System_Hazards.png" />
            </div>
            <div class="imagecaption">
              <p class="caption">
                <b>Figure
                1.1.2-A</b><a href="http://127.0.0.1:63320/node?ref=r%3Af484f3cb-b75d-4857-b03a-36f42bd7a5b9%28_100_Patterns%29%2F3666423621007706606" class="originalNode" title="open in MPS"></a>
              </p>
            </div>
          </div>
          <p class="body">
            <b>Problem and Solution</b>&nbsp;&nbsp;The intent of this pattern is to provide a top level decomposition for the safety argument of a system. In particular, the pattern provides the context for a software safety argument constructed from the Software Safety Pattern Catalogue. The focus for the argument is the identification of hazards and the assessment of the associated risks. This pattern identifies the three main claims which must be satisfied to show system safety; Valid Safety Requirements, Acceptable Levels of Risks, and Traceability of Safety Requirements and Safety Evidence. The pattern provides a suitable context and approach for developing a software safety argument.
          </p>
          <p class="body">
            <b>Context</b>&nbsp;&nbsp;The starting point of this pattern is to have clearly identified the components of the overall system, and their functional contributions to the overall system are understood. In order to apply this pattern it is necessary to have access to a definition of ‘acceptably safe’ for the 
            Context DefnAccSafe
            context. This definition is typically provided by the appropriate regulatory authority, standards or through investigations by safety engineers, including discussions with customers.<br/>
This definition should encapsulate some form of 
            GSN Document ALARP
            consideration, which would permeate through the rest of the pattern and argument. System-level and Component-level (Software, Hardware and Other) hazard analysis are required to determine the contributions of the components to system hazards.
          </p>
          <p class="body">
            <b>Participants &amp; Collaborations</b>&nbsp;&nbsp;The pattern contains the following <strong class="bold">participants</strong>:<br/>
<strong class="bold">
            Goal SystemSafe
            :</strong> The overall objective of the argument – to provide sufficient support for the claim that the System is acceptably safe to operate.<br/>
<strong class="bold">
            Context SysDefn
            :</strong>This model should give a clear definition of the system. From the model it should be possible to identify the system level hazards.<br/>
<strong class="bold">
            Context DefnAccSafe
            :</strong>To be able to argue that the claim is upheld, it is necessary to give a definition for the term ‘acceptably safe’.<br/>
This may come from a<br/>
standard or regulatory body. The definition will be the initial basis from which hazard assessment is made and an argument is generated with respect to the acceptability of the hazards.<br/>
<strong class="bold">
            Goal ReqValid
            :</strong>This claim asserts that the identified set of safety requirements is applicable (in the correct context) to the system, that they are complete and they are not mutually exclusive.<br/>
<strong class="bold">
            Goal HazAccept
            :</strong>This claim asserts the goal that all hazards at the system level have a risk which is acceptably safe as defined by DefnAccSafe.<br/>
<strong class="bold">
            Goal Traceability
            :</strong>This claim asserts that it is explicitly visible that the safety requirements have been satisfied through the safety evidence. This enables verification of the complete implementation of the system.<br/>
<strong class="bold">
            Context SysHaz
            :</strong>This context identifies the System Level Hazards upon which the HazAccept claim is based. These hazards form a hazard log, which identifies all unsafe behaviours of the system within its operating context.<br/>
<strong class="bold">
            Strategy ArgSWHWOther
            :</strong>This argument decomposes the System Level Hazards across the Hardware, Software and Other Parts of the system. This identifies what part(s) of the system contributes to each individual hazard.<br/>
<strong class="bold">
            Justification DependExplicit
            :</strong>The argument ArgSWHWOther is justified, so long as the dependencies between Hardware, Software and Other Parts of the System are explicitly documented. This encapsulates the mitigation of particular component failures through other means.<br/>
<strong class="bold">
            Goal HWContribAccept
            :</strong>This claim asserts that the Hazards associated with the Hardware component of the system are safe with respect to the definition given in DefnAccSafe.<br/>
<strong class="bold">
            Goal SWContribAccept
            :</strong>This claim asserts that the Hazardous Functions associated with the Software component of the system are safe with respect to the definition given in DefnAccSafe.<br/>
<strong class="bold">
            Goal OtherContribAccept
            :</strong>This context gives the safety requirements which are related to the other components of the system.<br/>
These can be either through other<br/>
component causes or through derived requirements due to cross dependencies.<br/>
<strong class="bold">
            Context OtherDefn
            :</strong>This Other Components Definition should give a clear description of the other components of the system. From the model it should be possible to identify the contribution of other components to system level hazards.<br/>
<strong class="bold">
            Context OtherContrib
            :</strong>This claim asserts that the Hazards associated with the Other components of the system are safe with respect to the definition given in DefnAccSafe.<br/>
<strong class="bold">
            Context HWDefn
            :</strong>This Hardware Definition should give a clear description of the system hardware. From the model it should be possible to identify the hardware contributions to system level hazards.<br/>
<strong class="bold">
            Context HWContrib
            :</strong>This context gives the safety requirements which are related to the hardware. These can be either through hardware causes or through derived requirements due to cross dependencies.<br/>
<strong class="bold">Context: SWDefn</strong>This Software Definition should give a clear description of the system software. From the model it should be possible to identify the software contribution to system level hazards.<br/>
<strong class="bold">Context: SWContrib</strong>This context gives the safety requirements which are related to the software. These can be either through software causes or through derived requirements due to cross dependencies.<br/>
<br/>
<code class="code">Collaborations: </code><br/>
• The context SysDefn model should be suitable for identifying the System Level Hazards for 
            Context SysHaz
            .<br/>
• The 
            Context HWDefn
            , in combination with
            Context SysHaz
            , should be suitable for identifying the hardware contributions to system level hazards for 
            Context HWContrib
            <br/>
• The context SWDefnin combination with
            Context SysHaz
            , should be suitable for identifying the software contributions to system level hazards for
            Context HWContrib
            .<br/>
• The 
            Context OtherContrib
            , in combination with
            Context SysHaz
            , should be suitable for identifying the other components contributions to system level hazards for 
            Context OtherContrib
            <br/>
• 
            Goal HazAccept
            , 
            Goal HWContribAccept
            , 
            Goal SWContribAccept
            , 
            Goal OtherContribAccept
             and SWHazAccept are all dependent on the definition of acceptably safe in 
            Context DefnAccSafe
            <br/>
• 
            Context HWContrib
            , context SWContrib and 
            Context OtherContrib
            discharge the justification given in
            Justification DependExplicit
            
          </p>
          <p class="body">
            <b>Implementation</b>&nbsp;&nbsp;This pattern should be instantiated in a Top Down fashion. All goals, contexts and models should be instantiated before continuing to a lower level in the pattern. <br/>
After instantiating this pattern a number of undeveloped goals will remain: <br/>
• 
            Goal ReqValid
            &amp; 
            Goal Traceability
             In accordance with the main objective of the pattern, these goals must be developed to give a complete safety argument for the system.<br/>
• 
            Goal HWContribAccept
            , 
            Goal SWContribAccept
            &amp; 
            Goal OtherContribAccept
             To complete the decomposition of 
            Strategy ArgSWHWOther
             these three goals need to be decomposed and satisfied. As this pattern provides context for the development of a software safety argument.  <br/>
<br/>
<code class="code">Possible Pitfalls</code><br/>
• Not identifying all possible system level hazards may lead to missing software safety requirements, which in turn may lead to software failure modes being missed.<br/>
• Not identifying all dependencies between software, hardware and other parts of the system may cause derived safety requirements to be missed. This would lead to assumptions about mitigation not being discharged.
          </p>
          <p class="body">
            <b>Related patterns &amp; Known Uses</b>&nbsp;&nbsp;Hazardous Software Failure Mode Decomposition – This pattern can be used to decompose the undeveloped 
            Goal SWContribAccept
            .<br/>
This pattern forms part of a software safety argument pattern catalogue cited at the end of this document, which includes the following patterns: <br/>
Component Contributions to System Hazards <br/>
Hazardous Software Failure Mode Decomposition <br/>
Hazardous Software Failure Mode Classification <br/>
Software Safety Argument Approach <br/>
Absence of Omission Hazardous Failure Mode <br/>
Absence of Commission Hazardous Failure Mode <br/>
Absence of Early Hazardous Failure Mode <br/>
Absence of Late Hazardous Failure Mode <br/>
Absence of Value Hazardous Failure Mode <br/>
Effects of Other Components <br/>
Handling of Software Failure <br/>
Mode Handling of Hardware/Other Component Failure Mode
          </p>
          <p class="body">
            <strong class="bold">Note:</strong> Pattern and documentation taken from: Weaver, R.. “The Safety of Software - Constructing and Assuring Arguments.” (2003).
          </p>
        </div>
        <div>
          <h3 id="sid7893292664124646102" class="section">1.1.3 Fault Tree Evidence</h3>
          <div class="imagecontainer border" id="sid5866579837810790031">
            <div class="imageWithBorder">
              <img src="../img/SafetyPatternsCatalogue_Faul_Tree_Evidence.png" />
            </div>
            <div class="imagecaption">
              <p class="caption">
                <b>Figure
                1.1.3-A</b><a href="http://127.0.0.1:63320/node?ref=r%3Af484f3cb-b75d-4857-b03a-36f42bd7a5b9%28_100_Patterns%29%2F7893292664124621845" class="originalNode" title="open in MPS"></a>
              </p>
            </div>
          </div>
          <p class="body">
            <b>Problem and Solution</b>&nbsp;&nbsp;The intent of this pattern is to show the nature of the claims that can be made from a fault tree representation of the causes of a condition.<br/>
The motivation behind the pattern is to improve understanding of the role of Fault Tree Analysis as a form of supporting evidence within an overall safety argument.
          </p>
          <p class="body">
            <b>Context</b>&nbsp;&nbsp;This pattern can be applied wherever: <br/>
• A fault tree for the condition exists – i.e. the skills for the construction and validation of such a casual model are available.<br/>
• 
            Assumption A1
             and 
            Justification J1
             can be discharged <br/>
• Fault Tree Analysis is an accepted as a form of evidence to be used within a safety argument (i.e. it is accepted and recognised by industry and regulatory standards)
          </p>
          <p class="body">
            <b>Participants &amp; Collaborations</b>&nbsp;&nbsp;The pattern contains the following <strong class="bold">participants</strong>:<br/>
<strong class="bold">
            Solution Sn1
            :</strong> This solution should be instantiated to refer to a Fault Tree representation of the causes of condition X. (X is the condition of interest for the purposes of this pattern).<br/>
<strong class="bold">
            Goal G1
            : </strong>Based on the causal model provided by the fault tree (
            Solution Sn1
            ) this goal can be instantiated to summarise the causes of condition X. This could be in the form of a list of causes (e.g. “Causes of X are pump failure, valve failure and processor failure”). Alternatively it could describe the nature of the causes identified by 
            Solution Sn1
             (e.g. “Causes of X are all physical failures”). This is a qualitative claim regarding the structure of the fault tree.<br/>
<strong class="bold">
            Goal G2
            : </strong>Where numerical probabilities have been provided for the basic failure events within the fault tree (
            Solution Sn1
             ) and probabilistic analysis has been possible, a (quantitative) claim can be put forward regarding the probability of condition X occurring. For conventional Fault Tree Analysis, such a claim relies heavily upon the 
            Assumption A1
            .<br/>
<strong class="bold">
            Goal G3
            : </strong>Where it is borne out by the causal model provided by the fault tree (
            Solution Sn1
            ) this goal can be instantiated to state that no single point of failure can lead to the condition X, i.e. the number of conditions in the set of necessary and sufficient causes of X is &gt;1.<br/>
<strong class="bold">
            Assumption A1
            : </strong>This assumption underpins the claims of both 
            Goal G2
             and 
            Goal G3
            . If this assumption does not hold, the probabilistic analysis of the fault tree would provide a misleading calculation of Condition X probability (hence challenging 
            Goal G2
            ). It may also mean that a common failure mode exists between basic events, thus challenging 
            Goal G3
            .<br/>
<strong class="bold">
            Justification J1
            : </strong>All of the claims (
            Goal G1
            , 
            Goal G2
             and 
            Goal G3
            ) are fallacious if this justification does not hold. For the fault tree to be a valid piece of supporting evidence for a safety argument it must be true that it presents an accurate and truthful causal model for X. For example, it must be consistent with design descriptions, operational evidence and other safety analyses.<br/>
<br/>
<code class="code">Collaborations: </code><br/>
• The 
            Goal G3
             can only be made if this is an observed property of 
            Solution Sn1
            <br/>
• 
            Goal G1
             and 
            Goal G3
             should not contradict each other
          </p>
          <p class="body">
            <b>Implementation</b>&nbsp;&nbsp;• Start by instantiating 
            Solution Sn1
             to refer to the fault tree constructed for condition X.<br/>
• Check that the independence
            Assumption A1
             holds.<br/>
• Support 
            Justification J1
             by ensuring that the validity of the tree is checked.<br/>
• Based upon cut set analysis of the fault tree, decide whether it is possible / appropriate to instantiate 
            Goal G3
            .<br/>
• If it is appropriate, instantiate 
            Goal G1
             to summarise the minimal causes identified for the tree.<br/>
• Where probabilistic analysis of the tree is possible, summarise the results through instantiating 
            Goal G2
            .<br/>
<br/>
<code class="code">Possible Pitfalls</code><br/>
• Failing to support the independence 
            Assumption A1
             <br/>
• Presenting a fault tree 
            Solution Sn1
             that does not support the justification J1. If the validity of the fault tree is not believed, then the claims derived from that fault tree will be questionable.
          </p>
          <p class="body">
            <b>Related patterns &amp; Known Uses</b>&nbsp;&nbsp;<code class="code">Known uses: Figure 126 of Appendix A (Nuclear Trip System Safety Case) from &quot;Arguing Safety – A Systematic Approach to Managing Safety Cases&quot;, Tim Kelly</code> <br/>
<code class="code">Related Patterns: Markov Model Evidence</code>
            
          </p>
        </div>
        <div>
          <h3 id="sid3666423621007720724" class="section">1.1.4 Hazard Avoidance Pattern</h3>
          <div class="imagecontainer border" id="sid5866579837810790350">
            <div class="imageWithBorder">
              <img src="../img/SafetyPatternsCatalogue_Hazard_Avoidance_Pattern.png" />
            </div>
            <div class="imagecaption">
              <p class="caption">
                <b>Figure
                1.1.4-A</b><a href="http://127.0.0.1:63320/node?ref=r%3Af484f3cb-b75d-4857-b03a-36f42bd7a5b9%28_100_Patterns%29%2F7893292664124621479" class="originalNode" title="open in MPS"></a>
              </p>
            </div>
          </div>
          <p class="body">
            <b>Problem and Solution</b>&nbsp;&nbsp;Patterns can emerge at many different levels in the safety argument and at varying degrees of specificity. At the highest level it is possible to identify a number of basic argument structures that are used to decompose ill-defined system safety requirements. In this pattern, the implicit definition of ‘safe’ is ‘hazard avoidance’. 
          </p>
          <p class="body">
            <b>Context</b>&nbsp;&nbsp;The pattern is deliberately general – it can be readily understood and have wide applicability across technologies and regulatory contexts. 
          </p>
          <p class="body">
            <b>Participants &amp; Collaborations</b>&nbsp;&nbsp;The requirement
            Goal G1
            is addressed by arguing that all identified hazards have been addressed 
            Strategy S1
            . This strategy can only be executed in the context of some knowledge of plausible hazards, e.g. identified by Hazard Analysis. Given this information 
            Context C1
            , identifying n hazards, n sub-goals of the form G2 can be constructed. The argument then progresses from these ‘hazard avoidance’ goals. 
          </p>
          <p class="body">
            <b>Related patterns &amp; Known Uses</b>&nbsp;&nbsp;<code class="code">Pattern and documentation taken from: Kelly, Tim. (2001). Arguing Safety -- A Systematic Approach to Managing Safety Cases Timothy Patrick Kelly. </code>.
          </p>
        </div>
        <div>
          <h3 id="sid7893292664124639090" class="section">1.1.5 Hazard Directed Integrity Level Argument</h3>
          <div class="imagecontainer border" id="sid5866579837810790631">
            <div class="imageWithBorder">
              <img src="../img/SafetyPatternsCatalogue_Hazard_Directed_Integrity_Level_Argument.png" />
            </div>
            <div class="imagecaption">
              <p class="caption">
                <b>Figure
                1.1.5-A</b><a href="http://127.0.0.1:63320/node?ref=r%3Af484f3cb-b75d-4857-b03a-36f42bd7a5b9%28_100_Patterns%29%2F1456418960127177748" class="originalNode" title="open in MPS"></a>
              </p>
            </div>
          </div>
          <p class="body">
            <b>Problem and Solution</b>&nbsp;&nbsp;This pattern is intended to argue that a (sub)system has been developed to an integrity level appropriate to the hazards to which the system contributes.<br/>
The motivation for this pattern was to provide an argument where the overall objective was expressed in terms of the hazards involved and to show how this was then translated into integrity level requirements. <br/>
The top level objective, being expressed in terms of hazards and associated hazard classes, can be more readily integrated with an overall system level argument.
          </p>
          <p class="body">
            <b>Context</b>&nbsp;&nbsp;The starting point of this pattern is to have clearly identified a set of subsystems in an overall system. This pattern should be instantiated for each subsystem identified. <br/>
In order to instantiate the pattern the following contextual information is required: • C1 – A description of how this subsystem can contribute to system level hazards<br/>
• C3 – Development rules / guidelines for each integrity level that set out the development practices required.<br/>
• C4 – Rules that, given a hazard classification, can be used to set a corresponding integrity level<br/>
• C5 – The results of some analysis that identify the subsystems on which the subsystem in question depends. <br/>
General Issues: The pattern is applicable in an environment where the concepts of Hazard Classification, Integrity Level and Subsystem are defined, understood and accepted as a means of arguing development integrity.
          </p>
          <p class="body">
            <b>Participants &amp; Collaborations</b>&nbsp;&nbsp;The pattern contains the following <strong class="bold">participants</strong>:<br/>
<strong class="bold">
            Goal G1
            :</strong> Having identified how the functionality provided by a subsystem (described by 
            Context C2
            ) can contribute to system level hazards (
            Context C1
            ) and having identified the Hazard Class associated with those system hazards it is possible to set out a goal of the form @go
            Goal G1
            . The terms {Subsystem X} and the Hazard Class {n} should be instantiated with real values. It is the overall objective of this pattern to support the claim made by 
            Goal G1
            .<br/>
<strong class="bold">
            Goal G2
            : </strong>This goal provides the principal support for the claim G1 – i.e. that the subsystem has been developed to a particular integrity level. The appropriate integrity level for the Hazard Class {n} stated in 
            Goal G1
             is defined by the rules for integrity level assignment referred to by 
            Context C4
             (e.g. a Hazard Risk Index Matrix). In order to say that the subsystem has been developed to a particular Integrity Level it is also necessary to refer to the development rules that apply for each integrity level – this is done by instantiating the context reference @conte
            Context C3
            . Appropriate argument / evidence must be placed in support of this goal.<br/>
<strong class="bold">
            Context C1
            : </strong>This context should be instantiated to refer to a source of information that describes how the functionality implemented by the subsystem can contribute to system level hazards (e.g. System level Safety Analysis or Subsystem level Hazard Analysis)<br/>
<strong class="bold">
            Context C2
            : </strong>This context should be instantiated to refer to a description of the subsystem in question – in particular, one that describes the functions implemented by the subsystem.<br/>
<strong class="bold">
            Context C3
            : </strong>This context should be instantiated to refer to development rules defined for each integrity level (i.e. that define the technology, tools and techniques that are appropriate)<br/>
<strong class="bold">
            Context C4
            : </strong>This context should be instantiated to refer to the rules used for integrity level assignment based on Hazard Classification. Usually these rules would be expressed as some form of Hazard Risk Index Matrix that determines the appropriate integrity level given the severity and likelihood of an accident attributable to a system hazard.<br/>
<strong class="bold">
            Goal G3
            : </strong>In addition to the claim put forward by G2 it is necessary to claim that the integrity of the subsystem is not violated (and is preserved) by the environment in which the subsystem operates.<br/>
<strong class="bold">
            Strategy S1
            : </strong>This strategy sets out the argument approach to be used in support of 
            Goal G3
            . The strategy is to argue that all subsystems on which the subsystem in question {Subsystem X} depends (identfied to by the context reference 
            Context C5
            ) are also developed to an appropriate integrity level. For each subsystem identified it is necessary to put forward a goal either of the form @goal
            Goal G4
             – claiming that the subsystem is developed to an integrity level the same or higher than that of {X} – or 
            Goal G5
             – that the subsystem is of lower integrity but in accordance with the assignment rules referred to by 
            Context C4
            .<br/>
<strong class="bold">
            Context C5
            : </strong>This context should be instantiated as a reference to the description of all subsystems {Y} on which the subsystem {X} depends. An analysis of dependencies between subsystems must be performed to provide this information. This information could be derived from a functional dependency diagram.<br/>
<strong class="bold">
            Goal G4
            : </strong>This is one of the two possible claims that could be made for a subsystem {Y} on which {X} depends. 
            Goal G4
             claims that {Y} is developed to the same or higher integrity level as {X}. This claim must be substantiated by further argument / evidence.<br/>
<strong class="bold">
            Goal G5
            : </strong>This is one of the two possible claims that could be made for a subsystem {Y} on which {X} depends. 
            Goal G5
             claims that {Y} is developed to a lower integrity level than {X} as allowed by the rules referred to by 
            Context C4
            .<br/>
<br/>
<br/>
<code class="code">Collaborations:</code><br/>
• 
            Context C1
             identifies the causal relationship between a subsystem’s function and system level hazards – making it possible to identify the Hazard Class that should be associated with the subsystem.<br/>
• 
            Context C3
             provides rules that enables the Integrity Level claim of G2 to be derived from the Hazard Class claim of G1.<br/>
• 
            Context C4
             defines what it means to say that a subsystem has been ‘developed to’ a particular integrity level (as is claimed in goal
            Goal G2
            ). (One would therefore imagine the information referred to by 
            Context C4
             would provide the structure of the argument and evidence used in supporting
            Goal G2
            .)<br/>
• 
            Goal G2
             and
            Goal G3
             work together. It is no use claiming the integrity of an individual subsystem if that integrity is potentially violated by the environment in which it is placed.<br/>
• 
            Context C5
            provides the basis (list of subsystems) for instantiating the argument strategy defined by
            Strategy S1
            .<br/>
• An either/or relationship exists between the goals
            Goal G4
             and 
            Goal G5
             (as denoted by the Choice symbol). However, there should be (in total) n of the goals of type 
            Goal G4
             or 
            Goal G5
            , where n is the number of subsystems on which {X} depends.
          </p>
          <p class="body">
            <b>Implementation</b>&nbsp;&nbsp;Start by identifying 
            Context C1
             and 
            Context C2
            ; State 
            Goal G1
            ; Use the assignment rules set out by 
            Context C4
             to state the goals 
            Goal G2
             and 
            Goal G3
            . Having stated 
            Goal G3
            , perform the analysis that provides the information referred to by 
            Context C5
            . Using the list of subfunctions identified by 
            Context C5
             develop the strategy S1 by stating (n) goals of the form 
            Goal G4
             or 
            Goal G5
            .<br/>
When it comes to supporting 
            Strategy S1
            , the integrity levels of the subsystems on which {X} depends, and therefore the choice between 
            Goal G4
             and 
            Goal G5
            , will be defined by the concurrent instantiation of this pattern for each of these other systems (i.e. the Hazard Class of related hazards etc.).
          </p>
          <p class="body">
            <b>Related patterns &amp; Known Uses</b>&nbsp;&nbsp;<code class="code">Known uses:</code> Aircraft Cockpit Display System Argument<br/>
<code class="code">Related Patterns: </code>ALARP Pattern – a pattern that addresses hazards according the levels of risk they pose<br/>
<code class="code">a and documentation taken from: Kelly, Tim. (2001). Arguing Safety -- A Systematic Approach to Managing Safety Cases Timothy Patrick Kelly. </code>
            
          </p>
        </div>
      </div>
      <div>
        <h2 id="sid3859986046039743616" class="section">1.2  Fault/Failure-Based Argument Patterns</h2>
        <div>
          <h3 id="sid2524223438958843133" class="section">1.2.1  Extended / Hierarchical Physical Decomposition Pattern</h3>
          <div class="imagecontainer border" id="sid5866579837810791094">
            <div class="imageWithBorder">
              <img src="../img/SafetyPatternsCatalogue_Extended_Hierarchical_Physical_Decomposition_Pattern.png" />
            </div>
            <div class="imagecaption">
              <p class="caption">
                <b>Figure
                1.2.1-A</b><a href="http://127.0.0.1:63320/node?ref=r%3Af484f3cb-b75d-4857-b03a-36f42bd7a5b9%28_100_Patterns%29%2F3666423621007704568" class="originalNode" title="open in MPS"></a>
              </p>
            </div>
          </div>
          <p class="body">
            <b>Problem and Solution</b>&nbsp;&nbsp;The intent of this pattern is the same as for the physical architecture breakdown pattern, i.e., to assure that failure hazards of a system have been sufficiently mitigated. The pattern was created to extend the physical architecture breakdown pattern, by considering hierarchy in the system structure.
          </p>
          <p class="body">
            <b>Context</b>&nbsp;&nbsp;This pattern is mainly applicable in the context of failure hazards, and when the failure hazard mitigation claim is made in the context of a system which has a physical architecture. In addition to this, the pattern can be applied when there is a nested hierarchy, i.e., when a system has several tiers of subsystems, components, etc.
          </p>
          <p class="body">
            <b>Participants &amp; Collaborations</b>&nbsp;&nbsp;The main elements of the extended physical decomposition pattern are identical to those of the physical architecture breakdown pattern.<br/>
Comparing them, we see that the extended physical decomposition pattern introduces a choice of strategies ( and 
            Strategy S2
            ) when addressing the claim of failure hazard mitigation at either the system or subsystem level. Hierarchy in the physical architecture is addressed by iterating on over the parent strategy of argument over the physical architecture breakdown (
            Strategy S1
            ). 
            Strategy S2
            , which is yet to be instantiated, represents any admissible set of failure mitigation strategies at the system/sub-system level, e.g., redundancy, design diversity, failure masking, etc.<br/>
<br/>
<strong class="bold">Collaborations:</strong><br/>
As indicated, the main difference between the extended physical decomposition pattern and the physical architecture breakdown pattern is the choice of strategies with which to develop the main claim and its sub-claims, in the pattern. Whereas in the latter, only one strategy (
            Strategy S1
            ) is available, in the former, the top-level claim 
            Goal G1
             can be developed either by argument over physical breakdown (
            Strategy S1
            ) or by invoking any appropriate strategy for failure mitigation (
            Strategy S2
            ). For the collaboration between the remaining elements,
          </p>
          <p class="body">
            <b>Implementation</b>&nbsp;&nbsp;In addition to the elements instantiated as in the physical architecture breakdown pattern from the mentioned publication at the end of this document, on instantiating the extended physical decomposition pattern, strategy S1 is also instantiated, where an appropriate failure mitigation strategy {r :: strategy} is referenced.
          </p>
          <p class="body">
            <b>Related patterns &amp; Known Uses</b>&nbsp;&nbsp;<code class="code">Pattern and documentation taken from: Denney, Ewen &amp; Pai, Ganesh. (2015). Safety Case Patterns: Theory and Applications. 10.13140/2.1.1950.4161. </code>  
          </p>
        </div>
        <div>
          <h3 id="sid2524223438958840483" class="section">1.2.2 Fault Free Pattern</h3>
          <div class="imagecontainer border" id="sid5866579837810791255">
            <div class="imageWithBorder">
              <img src="../img/SafetyPatternsCatalogue_Fault_Free_Software_Pattern.png" />
            </div>
            <div class="imagecaption">
              <p class="caption">
                <b>Figure
                1.2.2-A</b><a href="http://127.0.0.1:63320/node?ref=r%3Af484f3cb-b75d-4857-b03a-36f42bd7a5b9%28_100_Patterns%29%2F7893292664124620624" class="originalNode" title="open in MPS"></a>
              </p>
            </div>
          </div>
          <p class="body">
            <b>Problem and Solution</b>&nbsp;&nbsp;At lower levels in the safety case argument, patterns also emerge. For example, when arguing the safety of software it is often common to claim a level of software integrity from an appeal to having used best practice tools, techniques and methods during development and testing. Other common argument structures emerge from the use of particular techniques. For example, to support the claim that a particular software condition cannot arise, a pattern could be identified showing the typical use of either formal verification, Software Fault Tree Analysis (SFTA), or black box testing. <br/>
The Fault Free Software pattern aims to prove that a software element of system is &apos;fault-free&apos;.
          </p>
          <p class="body">
            <b>Context</b>&nbsp;&nbsp;The pattern is deliberately general – it can be readily understood and have wide applicability across technologies and regulatory contexts. 
          </p>
          <p class="body">
            <b>Participants &amp; Collaborations</b>&nbsp;&nbsp;In this pattern, the claim that the software element in a system is ‘fault free’ 
            Goal G1
             is supported by two main strands of argument (
            Strategy S1
             and 
            Strategy S2
            ). 
            Strategy S1
             is arguing safety over positive properties of the software. Over a list ( 
            Context C3
            )  of identified hazardous software conditions (e.g. “Controller demands speed greater than maximum safe speed”) the m sub-goals of the form G3 are expressed, to argue that these hazards can only occur through physical component failures. 
            Strategy S2
             is arguing safety through avoidance of negative properties of the software. Over a list ( 
            Context C4
            ) of identified software requirements (e.g. “Operation will not start if operator detected near machinery”) the n sub-goals of the form 
            Goal G2
             are expressed to argue that these properties are enforced in the software. In order that this pattern will be appropriately applied, the context of the pattern is made clear through the elements 
            Context C1
             and 
            Context C2
             - both defining key terms in the top-level claim. 
          </p>
          <p class="body">
            <b>Related patterns &amp; Known Uses</b>&nbsp;&nbsp;<code class="code">Known uses: Kelly, Tim. (2001). Arguing Safety -- A Systematic Approach to Managing Safety Cases Timothy Patrick Kelly. </code> <br/>
The ALARP (As-Low-As-Reasonably-Practicable) Pattern provides a more structured approach to presenting a ‘Hazard Avoidance’ argument (See Hazard Avoidance Pattern) by showing differing treatment of hazards according to their associated risk.
          </p>
        </div>
        <div>
          <h3 id="sid81587047679133879" class="section">1.2.3 Handling of Hardware/Other Component Failure Mode</h3>
          <div class="imagecontainer border" id="sid5866579837810791509">
            <div class="imageWithBorder">
              <img src="../img/SafetyPatternsCatalogue_Handling_of_Hardware_Other_Component_Failure_ModePattern.png" />
            </div>
            <div class="imagecaption">
              <p class="caption">
                <b>Figure
                1.2.3-A</b><a href="http://127.0.0.1:63320/node?ref=r%3Af484f3cb-b75d-4857-b03a-36f42bd7a5b9%28_100_Patterns%29%2F3666423621007709621" class="originalNode" title="open in MPS"></a>
              </p>
            </div>
          </div>
          <p class="body">
            <b>Problem and Solution</b>&nbsp;&nbsp;The intent of this pattern is to develop an argument that the software functionality can handle failures by hardware or other components. The motivation for this pattern is to be identify the ways in which failure modes are detected and handled by the software, depending upon the type of the failure mode.
          </p>
          <p class="body">
            <b>Context</b>&nbsp;&nbsp;This pattern identifies the claims about handling a hardware or other component failure mode by a piece of software functionality.<br/>
It assumes that the failure mode has been identified. It also assumes that the type of the failure mode can be determined and the software functionality that can handle the software can be identified.<br/>
The pattern is only applicable to failure modes that can be detected. Undetectable failure modes cannot be argued about using this pattern.
          </p>
          <p class="body">
            <b>Participants &amp; Collaborations</b>&nbsp;&nbsp;The pattern contains the following <strong class="bold">participants</strong>:<br/>
<strong class="bold">
            Goal HandlHH/OFM
            :</strong> The overall objective of the argument - to provide sufficient support for the claim that that a hardware or other component failure mode can be handled by another component.<br/>
<strong class="bold">
            Context HW/OtherDefn
            :</strong>This Hardware or Other Component Definition should give a clear description of the system hardware/other component. From the model it should be possible to determine how the failure mode effects the software and what type it is.<br/>
<strong class="bold">
            Context HH/OFM
            :</strong>This context identifies the Hazardous Hardware or Other Component Failure Mode, for which this pattern develops the handling argument.<br/>
<strong class="bold">
            Context HandleSWFunc
            :</strong>This context describes the software functionality that can detect and handle the occurrence of the failure mode.<br/>
<strong class="bold">
            Context SWDefn
            :</strong>This Software Definition should give a clear description of the system software. From the model it should be possible to determine how the software functionality can handle the failure of the hardware or other component.<br/>
<strong class="bold">
            Assumption Detectable
            :</strong>This argument assumes that the software failure mode is detectable. A handling argument cannot be generated for an undetectable failure mode.<br/>
This<br/>
<strong class="bold">
            Goal SWHandling
            :</strong>This claim asserts that the failure mode of a particular type can be handled by the software functionality<br/>
<strong class="bold">
            Context FMType
            :</strong>This context identifies the failure mode type which can be one of Omission, Commission, Early, Late and Value. The definitions of these failure modes are: <br/>
Omission: The service is never delivered <br/>
Commission: The service is delivered when not required <br/>
Early: The service occurs earlier than intended <br/>
Late: The service occurs later than intended <br/>
Value: The information (data) delivered has the wrong value<br/>
<strong class="bold">
            Strategy ArgDetHandl
            :</strong>This strategy describes the argument approach – decomposing across the detection and the handling of the failure mode.<br/>
<strong class="bold">
            Goal DetectHH/OFM{type}
            :</strong>This claim asserts that the failure mode can be detected by the software functionality.<br/>
<strong class="bold">
            Context DetectionMethods
            :</strong>This context provides the possible detection methods based upon the type of the failure mode.<br/>
Detection methods include: <br/>
Omission: Detection on Time (infinite threshold) <br/>
Commission: Detection on Time unexpected input (early) and/or unexpected input<br/>
Early: Detection on Time (Early) <br/>
Late: Detection on Time (Late) <br/>
Coarse Value: Detection on out of safe bounds (e.g. range, rate of change) <br/>
Subtle value failures can be detected if redundancy is employed.<br/>
<strong class="bold">
            Goal HandleHH/OFM{type}
            :</strong>This claim asserts that the failure mode can be handled by the software functionality<br/>
<strong class="bold">
            Context HandlingMethods
            :</strong>This context provides the possible handling methods based upon the type of the failure mode and whether redundancy is employed.<br/>
<br/>
<strong class="bold">Collaborations:</strong><br/>
• HW/ODefn, 
            Context HH/OFM
             should be suitable for identifying the type of the failure mode identified in
            Context FMType
            .<br/>
• 
            Context SWDefn
            , ContribSWFunc should be suitable for identifying the handling software functionality identified in
            Goal SWHandling
            .<br/>
• 
            Context DetectionMethods
            should be suitable for identifying the argument below 
            Goal DetectHH/OFM{type}
            .<br/>
• 
            Context HandlingMethods
            should be suitable for identifying the argument below 
            Goal DetectHH/OFM{type}
            .
          </p>
          <p class="body">
            <b>Implementation</b>&nbsp;&nbsp;This pattern should be instantiated in a Top Down fashion. All goals and contexts should be instantiated before continuing to a lower level in the pattern. It should be determined whether the failure mode is detectable before trying to decompose the argument. The type of the failure mode must be determined based upon the definitions provided in the Participants section.<br/>
After instantiating this pattern the following undeveloped goals will remain: <br/>
• 
            Goal DetectHH/OFM{type}
             and 
            Goal HandleHH/OFM{type}
            <br/>
 To satisfy the decomposition of HandlHH/OFM these goals need to be decomposed.<br/>
<br/>
<strong class="bold">Possible Pitfalls:</strong><br/>
• Not correctly determining whether the failure mode is detectable or undetectable can lead to an argument being generated that does not cover the failure mode in all possible contexts.<br/>
• Incorrectly identifying the software functionality that can handle the failure mode.<br/>
• Not correctly identifying the type of the failure mode can lead to an incorrect argument being developed.
          </p>
          <p class="body">
            <b>Related patterns &amp; Known Uses</b>&nbsp;&nbsp;Effects of Other Components – This pattern has undeveloped goals which can be the overall objective of Handling of Software Failure Mode.<br/>
This pattern forms part of a software safety argument pattern catalogue cited at the end of this document, which includes the following patterns: <br/>
Component Contributions to System Hazards <br/>
Hazardous Software Failure Mode Decomposition <br/>
Hazardous Software Failure Mode Classification <br/>
Software Safety Argument Approach <br/>
Absence of Omission Hazardous Failure Mode <br/>
Absence of Commission Hazardous Failure Mode <br/>
Absence of Early Hazardous Failure Mode <br/>
Absence of Late Hazardous Failure Mode <br/>
Absence of Value Hazardous Failure Mode <br/>
Effects of Other Components <br/>
Handling of Software Failure <br/>
Mode Handling of Hardware/Other Component Failure Mode
          </p>
          <p class="body">
            <strong class="bold">Note:</strong> Pattern and documentation taken from: Weaver, R.. “The Safety of Software - Constructing and Assuring Arguments.” (2003).
          </p>
        </div>
        <div>
          <h3 id="sid81587047679136567" class="section">1.2.4 Handling of Software Failure Mode</h3>
          <div class="imagecontainer border" id="sid5866579837810791971">
            <div class="imageWithBorder">
              <img src="../img/SafetyPatternsCatalogue_Handling_of_Software_Failure_Mode.png" />
            </div>
            <div class="imagecaption">
              <p class="caption">
                <b>Figure
                1.2.4-A</b><a href="http://127.0.0.1:63320/node?ref=r%3Af484f3cb-b75d-4857-b03a-36f42bd7a5b9%28_100_Patterns%29%2F3666423621007711624" class="originalNode" title="open in MPS"></a>
              </p>
            </div>
          </div>
          <p class="body">
            <b>Problem and Solution</b>&nbsp;&nbsp;The intent of this pattern is to develop an argument that a software failure mode can be handled by other components (software, hardware or other).<br/>
The motivation for this pattern is to be able to either identify requirements on the hardware or other component safety arguments, or to develop an argument about other software functionality that will detect and handle the failure.<br/>

          </p>
          <p class="body">
            <b>Context</b>&nbsp;&nbsp;This pattern identifies the claims about handling a software failure mode by parts of the system (hardware, other software functionality, other components) for a particular software failure mode.<br/>
It assumes that the failure mode has been identified, classified as a certain type and the Contributory Software Functionality has been identified. It also assumes the ability of the other parts of the system to handle the software failure mode can be identified. The pattern is only applicable to failure modes that can be detected. Undetectable failure modes cannot be argued about using this pattern.
          </p>
          <p class="body">
            <b>Participants &amp; Collaborations</b>&nbsp;&nbsp;The pattern contains the following <strong class="bold">participants</strong>:<br/>
<strong class="bold">
            Goal HandlHSFM{type}
            :</strong> The overall objective of the argument - to provide sufficient support for the claim that that a particular type of Software failure mode can be handled by another component.<br/>
<strong class="bold">
            Context HSFM
            :</strong>This context identifies the Hazardous Software Failure Mode, for which this pattern develops the handling argument.<br/>
<strong class="bold">
            Context ContribSWFunc
            :</strong>This context describes the software functionality that has a contributing effect to the cause of the software failure mode.<br/>
<strong class="bold">
            Context SafReqCSF
            :</strong>The safety requirements of the contributory software functionality are given as a basis for developing evidence.<br/>
<strong class="bold">
            Context ContextCSF
            :</strong>An assumption is made that only circumstances in which the Contributory Software Functionality (CSF) operates are considered during analysis of the failure mode.<br/>
<strong class="bold">
            Assumption Detectable
            :</strong>This argument assumes that the software failure mode is detectable. A handling argument cannot be generated for an undetectable failure mode.<br/>
<strong class="bold">
            Goal HWHandling_Hardware Safety Argument
            :</strong>This away goal to the hardware safety argument places a requirement on that argument that the Failure Mode can be handled by the hardware.<br/>
<strong class="bold">
            Goal OthHandling_Other Safety Argument
            :</strong>This away goal to the other component safety argument places a requirement on that argument that the Failure Mode can be handled by the other component<br/>
<strong class="bold">
            Goal SWHandling
            :</strong>This claim asserts that the software failure mode can be handled by another piece of software functionality<br/>
<strong class="bold">SWDefn:</strong>This Software Definition should give a clear description of the system software. From the model it should be possible to determine how the software functionality can handle the failure of the contributory software functionality.<br/>
<strong class="bold">
            Context HandleSWFunc
            :</strong>This context describes the software functionality that can detect and handle the occurrence of the software failure mode.<br/>
<strong class="bold">
            Strategy ArgDetHandl
            :</strong>This strategy describes the argument approach – decomposing across the detection and the handling of the software failure mode.<br/>
<strong class="bold">
            Goal HandlHSFM{type}
            :</strong>This context provides the possible handling methods based upon the type of the failure mode and whether redundancy is employed.<br/>
<strong class="bold">
            Goal DetectHSFM{type}
            :</strong>This claim asserts that the software failure mode can be detected by the other software functionality<br/>
<strong class="bold">
            Context HandlingMethods
            :</strong>This claim asserts that the software failure mode can be handled by the other software functionality<br/>
<strong class="bold">
            Context DetectionMethods
            :</strong>This context provides the possible detection methods based upon the type of the failure mode.<br/>
Detection methods include: <br/>
Omission: Detection on Time (infinite threshold) <br/>
Commission: Detection on Time (early) and/or unexpected input<br/>
Early: Detection on Time (Early) <br/>
Late: Detection on Time (Late) <br/>
Coarse Value: Detection on out of safe bounds (e.g. range, rate of change) <br/>
Subtle value failures can be detected if redundancy is employed.<br/>
<br/>
<strong class="bold">Collaborations:</strong> <br/>
• SWDefn, ContribSWFunc, 
            Context HSFM
             should be suitable for identifying the handling software functionality identified in HandleSWFunc.<br/>
•
            Context DetectionMethods
            should be suitable for identifying the argument below
            Goal DetectHSFM{type}
            .<br/>
•
            Context HandlingMethods
            ods should be suitable for identifying the argument below
            Goal HandlHSFM{type}
            .
          </p>
          <p class="body">
            <b>Implementation</b>&nbsp;&nbsp;This pattern should be instantiated in a Top Down fashion. All goals and contexts should be instantiated before continuing to a lower level in the pattern. It should be determined whether the failure mode is detectable before trying to decompose the argument. A choice (1-of-3) must be made about whether the handling of the software failure mode is provided by hardware, other software functionality or another component.<br/>
After instantiating this pattern the following undeveloped goals may remain:<br/>
•
            Goal DetectHSFM{type}
            and Handl
            Goal HandlHSFM{type}
            <br/>
 After instantiating this pattern one of two away goals may need to be satisfied: <br/>
• 
            Goal HWHandling_Hardware Safety Argument
            ,
            Goal OthHandling_Other Safety Argument
            <br/>
To satisfy the decomposition of HandlHSFM{type} the necessary goals need to be decomposed and the away goals satisfied.<br/>
<br/>
<br/>
• Not correctly determining whether the failure mode is detectable or undetectable can lead to an argument being generated that does not cover the failure mode in all possible contexts.<br/>
• Not correctly identifying the correct detection or handling approaches for the failure mode can lead to an incorrect argument being developed.<br/>
• Providing a requirement on the hardware or other component safety argument, which cannot be supported.
          </p>
          <p class="body">
            <b>Related patterns &amp; Known Uses</b>&nbsp;&nbsp;Software Argument Approach – This pattern has an undeveloped goal which can be the overall objective of Handling of Software Failure Mode.<br/>
This pattern forms part of a software safety argument pattern catalogue cited at the end of this document, which includes the following patterns: <br/>
Component Contributions to System Hazards <br/>
Hazardous Software Failure Mode Decomposition <br/>
Hazardous Software Failure Mode Classification <br/>
Software Safety Argument Approach <br/>
Absence of Omission Hazardous Failure Mode <br/>
Absence of Commission Hazardous Failure Mode <br/>
Absence of Early Hazardous Failure Mode <br/>
Absence of Late Hazardous Failure Mode <br/>
Absence of Value Hazardous Failure Mode <br/>
Effects of Other Components <br/>
Handling of Software Failure <br/>
Mode Handling of Hardware/Other Component Failure Mode
          </p>
          <p class="body">
            <strong class="bold">Note:</strong> Pattern and documentation taken from: Weaver, R.. “The Safety of Software - Constructing and Assuring Arguments.” (2003).
          </p>
        </div>
        <div>
          <h3 id="sid6723039987465357955" class="section">1.2.5 Hazardous Software Failure Mode Decomposition</h3>
          <div class="imagecontainer border" id="sid5866579837810792413">
            <div class="imageWithBorder">
              <img src="../img/SafetyPatternsCatalogue_Hazardous_Software_Failure_Mode_Decomposition_Pattern.png" />
            </div>
            <div class="imagecaption">
              <p class="caption">
                <b>Figure
                1.2.5-A</b><a href="http://127.0.0.1:63320/node?ref=r%3Af484f3cb-b75d-4857-b03a-36f42bd7a5b9%28_100_Patterns%29%2F3666423621007708506" class="originalNode" title="open in MPS"></a>
              </p>
            </div>
          </div>
          <p class="body">
            <b>Problem and Solution</b>&nbsp;&nbsp;The intent of this pattern is to provide a decomposition for the acceptability of software with respect to system level hazards. The pattern identifies the primary claims for developing a software safety argument from a hazard control perspective.<br/>
The motivation of this pattern was to identify the three primary claims which must be satisfied to show the acceptability of software; All software contributions have been identified, Acceptability of Hazardous Software Failure Modes, and Traceability of Safety Requirements and Safety Evidence.
          </p>
          <p class="body">
            <b>Context</b>&nbsp;&nbsp;This pattern follows a hazard directed breakdown of the software, and it assumes that hazard identification and analysis have been performed at a system level and it is possible to determine the contribution of the software to system level hazards. This pattern assumes that all dependencies between software, hardware and other parts of the system have been identified. If this is not done it may cause derived safety requirements to be missed. This would lead to assumptions about mitigation not being discharged.
          </p>
          <p class="body">
            <b>Participants &amp; Collaborations</b>&nbsp;&nbsp;The pattern contains the following <strong class="bold">participants</strong>:<br/>
<strong class="bold">
            Goal SWContribAccept
            :</strong> This claim asserts that the Hazardous Functions associated with the Software component of the system are safe with respect to the definition given in DefnAccSafe.<br/>
<strong class="bold">
            Context SWDefn
            :</strong>This Software Definition should give a clear description of the system software. From the model it should be possible to identify the software contribution to system level hazards.<br/>
<strong class="bold">
            Context SWContrib
            :</strong>This context identifies the software contributions to system level hazards, known as Hazardous Software Failure Modes<br/>
<strong class="bold">
            Goal SWContribIdent
            :</strong>This context gives the safety requirements which are related to the software. These can be either through software causes or through derived requirements due to cross dependencies.<br/>
<strong class="bold">
            Goal SWSRTraceability
            :</strong>This claim asserts that it is explicitly visible that the software safety requirements have been satisfied through the safety evidence. This enables verification of the complete implementation of the system.<br/>
<strong class="bold">
            Strategy ArgOverSWContrib
            :</strong>This provides that strategy of the software safety argument - decomposing the software hazard contribution across individual hazardous software failure modes.<br/>
<strong class="bold">
            Goal HSFMAccept
            :</strong>This claim provides the goal, which must be satisfied for each individual software hazard that has been identified.<br/>
<br/>
<strong class="bold">Collaborations:</strong><br/>
• The <strong class="bold">
            Context SWDefn
            :</strong> model, in combination with the system hazards, should be suitable for identifying the Hazardous Software Contributions for
            Context SWContrib
            .<br/>
• Software Hazardous Failure Modes identified in
            Context SWContrib
            , should form a complete set, as identified by the claim
            Goal SWContribIdent
            .<br/>
• The child goal instantiations of
            Goal HSFMAccept
             should cover all possible contributions by the software to system level hazards.
          </p>
          <p class="body">
            <b>Implementation</b>&nbsp;&nbsp;This pattern should be instantiated in a Top Down fashion. All goals, contexts and models should be instantiated before continuing to a lower level in the pattern.   <br/>
After instantiating this pattern a number of undeveloped goals will remain: <br/>
• 
            Goal SWContribIdent
            &amp; 
            Goal SWSRTraceability
             <br/>
In accordance with the main objective of the pattern, these goals must be developed to give a complete safety argument for the system.<br/>
• 
            Goal HSFMAccept
             <br/>
An argument must be developed about each individual instantiation of this goal.<br/>
<br/>
<strong class="bold">Possible Pitfalls:</strong><br/>
• Not identifying all possible software level contributions to system level hazards may lead to missing software safety requirements and hence may lead to hazardous software failure modes not being identified.<br/>
• While not a pitfall of this pattern, it is possible that all system level hazards have been identified
          </p>
          <p class="body">
            <b>Related patterns &amp; Known Uses</b>&nbsp;&nbsp;Hazardous Software Failure Mode Decomposition – This pattern can be used to decompose the undeveloped 
            Goal SWContribAccept
            .<br/>
This pattern forms part of a software safety argument pattern catalogue cited at the end of this document, which includes the following patterns: <br/>
Component Contributions to System Hazards <br/>
Hazardous Software Failure Mode Decomposition <br/>
Hazardous Software Failure Mode Classification <br/>
Software Safety Argument Approach <br/>
Absence of Omission Hazardous Failure Mode <br/>
Absence of Commission Hazardous Failure Mode <br/>
Absence of Early Hazardous Failure Mode <br/>
Absence of Late Hazardous Failure Mode <br/>
Absence of Value Hazardous Failure Mode <br/>
Effects of Other Components <br/>
Handling of Software Failure <br/>
Mode Handling of Hardware/Other Component Failure Mode
          </p>
          <p class="body">
            <strong class="bold">Note:</strong> Pattern and documentation taken from: Weaver, R.. “The Safety of Software - Constructing and Assuring Arguments.” (2003).
          </p>
        </div>
        <div>
          <h3 id="sid6723039987465359979" class="section">1.2.6 Software Argument Approach</h3>
          <div class="imagecontainer border" id="sid5866579837810792769">
            <div class="imageWithBorder">
              <img src="../img/SafetyPatternsCatalogue_Software_Argument_Approach_Pattern.png" />
            </div>
            <div class="imagecaption">
              <p class="caption">
                <b>Figure
                1.2.6-A</b><a href="http://127.0.0.1:63320/node?ref=r%3Af484f3cb-b75d-4857-b03a-36f42bd7a5b9%28_100_Patterns%29%2F3666423621007709092" class="originalNode" title="open in MPS"></a>
              </p>
            </div>
          </div>
          <p class="body">
            <b>Problem and Solution</b>&nbsp;&nbsp;The intent of this pattern is to identify the argument approach used for demonstrating the acceptability of the hazardous software failure mode. The argument can be made by showing Absence and/or Handling of the failure mode.<br/>
Arguments for the acceptably safe nature of a hazardous software failure mode can be made two ways.<br/>
As it is not possible to<br/>
determine a probability for systematic software failures, evidence must be provided that the failure mode is absent or can be handled if it does occur. The structure of the pattern allows for a mixture of both argument approaches, depending upon whether individually or together enough evidence can provided to support the claims.
          </p>
          <p class="body">
            <b>Context</b>&nbsp;&nbsp;This pattern identifies the argument approach for a particular software failure mode. It assumes that the failure mode has been identified and classified as a certain type.<br/>
It also assumes that<br/>
evidence can be generated about the absence or handling of the failure mode.
          </p>
          <p class="body">
            <b>Participants &amp; Collaborations</b>&nbsp;&nbsp;The pattern contains the following <strong class="bold">participants</strong>:<br/>
<strong class="bold">
            Goal HSFM{type}Accept
            :</strong> The overall objective of the argument – to provide sufficient support to the claim that the Hazardous Software Failure Mode of a particular type under consideration is acceptably safe.<br/>
<strong class="bold">
            Context HSFM
            :</strong>This context identifies the Hazardous Software Failure Mode, for which this pattern develops the argument approach.<br/>
<strong class="bold">
            Context SWDefn
            :</strong>This Software Definition should give a clear description of the system software. From the model it should be possible to determine the contributory software functionality in which the failure mode is manifested.<br/>
<strong class="bold">
            Context ContribSWFunc
            :</strong>This context describes the software functionality that may have a contributing effect to the cause of the software failure mode.<br/>
<strong class="bold">
            Goal AbsHSFM{type}
            :</strong>This claim asserts that the hazardous software failure mode does not exist in the software, and thus cannot contribute to the hazard occurring.<br/>
<strong class="bold">
            Goal HandlHSFM{type}
            :</strong>This claim asserts that the hazardous software failure mode occurring in the particular software functionality can be handled through other means.<br/>
<strong class="bold">
            Strategy ArgAbsHandl
            :</strong>This provides the strategy for arguing about the safety of the hazard. The argument can be decomposed by showing absence<br/>
and/or<br/>
handling of the failure mode.<br/>
<br/>
<br/>
<strong class="bold">Collaborations:</strong><br/>
• The contributory software functionality identified in 
            Context ContribSWFunc
             should be determined from the software definition (
            Context SWDefn
            ).<br/>
• ContribSW identifies the software functionality on which the
            Goal AbsHSFM{type}
            and 
            Goal HandlHSFM{type}
            claims are made.<br/>
• It is necessary for the goals 
            Goal AbsHSFM{type}
            ,
            Goal HandlHSFM{type}
             to be suitable for providing an argument about the acceptability of the failure mode.
          </p>
          <p class="body">
            <b>Implementation</b>&nbsp;&nbsp;To instantiate this pattern the means by which the argument is going to be satisfied should be chosen. The choice of the two claims (Absence and/or Handling) is an m of n selection. It is up to the implementer to choose what technique(s) will be used, depending upon the detail of the failure mode.<br/>
Where sufficient evidence cannot be generated about absence or handling of the failure mode alone, it is recommended that a combination of these two types of evidence is used.<br/>
After instantiating this pattern one or two undeveloped goals remain: <br/>
• 
            Goal AbsHSFM{type}
             &amp;/or 
            Goal HandlHSFM{type}
            <br/>
The above goal(s) must be developed to satisfy the decomposition of 
            Strategy ArgAbsHandl
            .<br/>
<br/>
<strong class="bold">Possible Pitfalls:</strong><br/>
• Selecting an argument approach for which evidence cannot be generated.
          </p>
          <p class="body">
            <b>Related patterns &amp; Known Uses</b>&nbsp;&nbsp;Hazardous Software Failure Mode Classification – This pattern provides a context for the overall objective 
            Goal HSFM{type}Accept
             <br/>
Absence of Omission Hazardous Failure Mode – This pattern can be used to decompose the undeveloped 
            Goal AbsHSFM{type}
            for a failure mode of type Omission. <br/>
Absence of Commission Hazardous Failure Mode – This pattern can be used to decompose the undeveloped 
            Goal AbsHSFM{type}
            for a failure mode of type Commission. <br/>
Absence of Early Hazardous Failure Mode – This pattern can be used to decompose the undeveloped
            Goal AbsHSFM{type}
            for a failure mode of type Early. <br/>
Absence of Late Hazardous Failure Mode – This pattern can be used to decompose the undeveloped
            Goal AbsHSFM{type}
             for a failure mode of type Late. <br/>
Absence of Value Hazardous Failure Mode – This pattern can be used to decompose the undeveloped
            Goal AbsHSFM{type}
             for a failure mode of type Value. <br/>
Handling of Software Failure Mode – This pattern can be used to decompose the undeveloped
            Goal HandlHSFM{type}
            .<br/>
<br/>
<br/>
This pattern forms part of a software safety argument pattern catalogue cited at the end of this document, which includes the following patterns: <br/>
Component Contributions to System Hazards <br/>
Hazardous Software Failure Mode Decomposition <br/>
Hazardous Software Failure Mode Classification <br/>
Software Safety Argument Approach <br/>
Absence of Omission Hazardous Failure Mode <br/>
Absence of Commission Hazardous Failure Mode <br/>
Absence of Early Hazardous Failure Mode <br/>
Absence of Late Hazardous Failure Mode <br/>
Absence of Value Hazardous Failure Mode <br/>
Effects of Other Components <br/>
Handling of Software Failure <br/>
Mode Handling of Hardware/Other Component Failure Mode
          </p>
          <p class="body">
            <strong class="bold">Note:</strong> Pattern and documentation taken from: Weaver, R.. “The Safety of Software - Constructing and Assuring Arguments.” (2003).
          </p>
        </div>
      </div>
      <div>
        <h2 id="sid1173803721179809910" class="section">1.3 Verification-based Argument Patterns</h2>
        <div>
          <h3 id="sid2186533634773259659" class="section">1.3.1 Property Assurance using formal evidence</h3>
          <div class="imagecontainer border" id="sid5866579837810793027">
            <div class="imageWithBorder">
              <img src="../img/SafetyPatternsCatalogue_hawkins_fm_verif_evidence.png" />
            </div>
            <div class="imagecaption">
              <p class="caption">
                <b>Figure
                1.3.1-A</b><a href="http://127.0.0.1:63320/node?ref=r%3Af484f3cb-b75d-4857-b03a-36f42bd7a5b9%28_100_Patterns%29%2F7954484994515679603" class="originalNode" title="open in MPS"></a>
              </p>
            </div>
          </div>
          <p class="body">
            <b>Problem and Solution</b>&nbsp;&nbsp;This pattern should be used to create arguments that formally defined properties of a D-MILS are satisfied by a MILS-AADL model of that system.
          </p>
          <p class="body">
            <b>Context</b>&nbsp;&nbsp;This pattern is applicable to any D-MILS system that uses a formal verification approach to prove properties of the system.
          </p>
          <p class="body">
            <b>Participants &amp; Collaborations</b>&nbsp;&nbsp;-
            Goal propSat
            : It is necessary to demonstrate that each of the formal properties specified in the MILS-AADL model is satisfied. This is done using a formal verification approach.<br/>
-
            Goal verifResults
            : The results of the formal verification are used to demonstrate that the formal property is satisfied. The type of formal technique used to verify the property will depend on the property itself.<br/>
-
            Context components
            : As part of the verification of the formal properties, formal requirements may be specified for components of the system that refine the formal system property. Components for which a requirement has been specified are referred to as trusted software components. The trusted software components are referred to from elsewhere in the D-MILS assurance case.<br/>
-
            Context enviroProps
            : As part of the verification of the formal properties, assumptions may be made regarding properties of the environment of the D-MILS system. The assumed environmental properties are referred to from elsewhere in the D-MILS assurance case.<br/>
-
            Context platformProps
            : As part of the verification of the formal properties, it may be necessary to make additional assumptions made about the properties of the D-MILS platform over and above the generic platform properties described in the DMILS platform pattern. The assumed platform properties are referred to from elsewhere in the D-MILS assurance case.<br/>
-
            Goal formalConf
            : As well as presenting the results of the formal verification, it is also necessary to demonstrate that there is sufficient confidence in the correctness of those formal verification results.<br/>
-
            Goal verification
            : The verification technique applied will be selected based upon the type of prop- erty to be verified. It must be demonstrated that the process of verification using the technique generates trustworthy results.<br/>
-
            Goal activityTrust_Process
            : A claim is made that the activity of performing the verification using the applied technique is sufficiently trustworthy. This claim is supported by an assurance case module for the verification process, which is an instantiation of the generic process argument pattern (see the process pattern in section 2.6 of the referenced paper at the end of this documentation). Where a process model of the verification activity is provided, the appropriate process model is selected according to the name of the technique used (as specified in the MILS-AADL model of the system).
          </p>
          <p class="body">
            <b>Related patterns &amp; Known uses</b>&nbsp;&nbsp;<br/>
The argument created from this pattern supports the argument created using the D-MILS system properties pattern and requires support from arguments created using the process argument pattern. This pattern is used along with other patterns from the publication referenced at the end of this documentation.
          </p>
          <p class="body">
            <strong class="bold">Note:</strong> Pattern and information has been taken from:<br/>
Integration of Formal Evidence and Expression in MILS Assurance Case. Technical Report D4.3, D-MILS Project, March 2015. http://www.d-mils.org/page/results.
          </p>
        </div>
      </div>
      <div>
        <h2 id="sid1173803721179809924" class="section">1.4 Requirements-based Argument Patterns</h2>
        <div>
          <h3 id="sid2524223438958841587" class="section">1.4.1  Requirements Breakdown Pattern</h3>
          <div class="imagecontainer border" id="sid5866579837810793512">
            <div class="imageWithBorder">
              <img src="../img/SafetyPatternsCatalogue_Requirements_Breakdown_Pattern.png" />
            </div>
            <div class="imagecaption">
              <p class="caption">
                <b>Figure
                1.4.1-A</b><a href="http://127.0.0.1:63320/node?ref=r%3Af484f3cb-b75d-4857-b03a-36f42bd7a5b9%28_100_Patterns%29%2F3666423621007704505" class="originalNode" title="open in MPS"></a>
              </p>
            </div>
          </div>
          <p class="body">
            <b>Problem and Solution</b>&nbsp;&nbsp;The requirements breakdown pattern provides a framework to represent the argument implicit in a requirements table, i.e., that requirements have been demonstrated by verification evidence.<br/>
There are two main motivations for this pattern: :<br/>
(1) provide an argument structure that shows how the claims entailed by requirements (in a requirements table) have been supported by the evidence generated from verification methods.<br/>
(2) be composed with the extended hazard directed breakdown pattern, i.e., by providing an argument structure to develop the claim in the extended hazard directed breakdown pattern that a safety requirement holds.
          </p>
          <p class="body">
            <b>Participants &amp; Collaborations</b>&nbsp;&nbsp;The main elements in this pattern are: <br/>
• <strong class="bold">Goals:</strong><br/>
– 
            Goal G1
            : The claim that a system/safety requirement holds; this is usually an entry in a requirements table and it refers to a requirement at a specific level of the system hierarchy.<br/>
– 
            Goal G2
            : The claim that a “lower-level” requirement holds; this is usually an entry in the requirements table following a system/safety requirement, at a lower level of the system hierarchy.<br/>
– 
            Goal G3
            : The claim that an allocated requirement holds. <br/>
– 
            Goal G4
            : The claim that refines either of the instantiated
            Goal G1
            ,
            Goal G2
            , or
            Goal G3
             using the verification method in 
            Strategy S3
            . This goal remains uninstantiated when the pattern is instantiated since its instantia- tion requires knowledge of the exact form of the claims made in its parent goals.<br/>
• <strong class="bold">Strategies:</strong><br/>
– 
            Strategy S1
            : Navigating to the lower-level requirements. <br/>
– 
            Strategy S2
            : Navigating to the allocated requirements. <br/>
– 
            Strategy S3
            : Application of a verification method.<br/>
• <strong class="bold">Context:</strong> <br/>
– 
            Context C1
            : Identifies the source of the requirement. <br/>
– 
            Context C2
            : Identifies the entity, i.e., system, subsystem, component model, etc. to which the requirement applies.<br/>
<strong class="bold">Evidence</strong> <br/>
– 
            Solution E1
            : The result from the verification method used in 
            Strategy S2
            , such that the claim made in 
            Goal G4
             is supported.<br/>
<br/>
bol<strong class="bold">Collaborations:</strong><br/>
The initial claim (
            Goal G1
            ) in the pattern is that a safety or system requirement for a system holds, made in the context of a system / subsystem to which the requirement applies (
            Context C2
            ). The source of the requirement (
            Context C1
            ) is also clarified. We develop the top-level claim using (at least) one of three strategies. Namely, (
            Strategy S1
            ) by argument over lower- level requirements, (
            Strategy S2
            ) by argument over allocated requirements, and (
            Strategy S3
            ) by argument by one or more verification methods. The consequent sub-claims are, respectively, (
            Goal G2
            ) that lower-level requirements are met, (
            Goal G3
            ) that the allocated requirements hold, and (
            Goal G4
            ) the refinement of the relevant parent claim (
            Goal G1
            , 
            Goal G2
             or 
            Goal G3
            ). The sub-claims
            Goal G2
             and 
            Goal G3
            are semantically of the same form as the top-level claim G1; hence, we can apply the same strategies used to develop . This is reflected as the loop links from 
            Goal G2
             and 
            Goal G3
             to their parent strategies. In addition, each of the three claims can be developed using one or more verification methods (
            Strategy S3
            ), the result of which provides the evidence (
            Solution E1
            ) needed to support the claims made.
          </p>
          <p class="body">
            <b>Implementation</b>&nbsp;&nbsp;This pattern can be composed with the extended hazard directed breakdown pattern to develop the claim in the latter that a safety requirement holds. We also apply this pattern to make explicit, the implicit argument in a requirements table that requirements have been demonstrated by verification evidence. Cer- tain elements of the requirements table, such as the source of the requirement and the system / subsystem / component to which the requirement applies, appear as the context elements 
            Context C1
             and 
            Context C2
            , when the pattern is instantiated. <br/>
<br/>
On instantiating the pattern, a number of goals and strategies of the following form are created: <br/>
• 
            Goal G1
            . System/Safety requirement {rs :: requirement} holds. There are as many goals of this form, as there are system/safety requirements in the requirements table.<br/>
• 
            Goal G2
            . Lower-level requirement {rl :: requirement} holds. There are as many goals of this form as there are lower-level requirements for each system/safety requirement.<br/>
• 
            Goal G3
            . Allocated requirement {ra :: requirement} holds. There are as many goals of this form as are allocated to each system/safety requirement.<br/>
• 
            Goal G4
            . {g :: goal ∣ 
            Goal G1
            , 
            Goal G2
            , 
            Goal G3
            , 
            Strategy S3
            }. This goal is uninstantiated and depends on the exact form of the claim in the parent goals 
            Goal G1
            , 
            Goal G2
             or 
            Goal G3
            . Depending on the number of verification methods used to develop each claim in either of 
            Goal G1
            , 
            Goal G2
            , 
            Goal G3
            , there are as many of these claims created as there are verification methods used. Thus,<br/>
• 
            Strategy S3
            . Argument by verification method {vm :: verificationMethod}. There are as many of these strategies instantiated as there are verification methods used for each of the system/safety, lower-level or allocated requirement.
          </p>
          <p class="body">
            <b>Related patterns &amp; Known Uses</b>&nbsp;&nbsp;<code class="code">Pattern and documentation taken from: Denney, Ewen &amp; Pai, Ganesh. (2015). Safety Case Patterns: Theory and Applications. 10.13140/2.1.1950.4161.</code>  
          </p>
        </div>
        <div>
          <h3 id="sid942157498040132670" class="section">1.4.2 Refinement of G2:HLRSAT</h3>
          <div class="imagecontainer border" id="sid5866579837810793139">
            <div class="imageWithBorder">
              <img src="../img/SafetyPatternsCatalogue_Refinement_of_G2_HLRSAT.png" />
            </div>
            <div class="imagecaption">
              <p class="caption">
                <b>Figure
                1.4.2-A</b><a href="http://127.0.0.1:63320/node?ref=r%3Af484f3cb-b75d-4857-b03a-36f42bd7a5b9%28_100_Patterns%29%2F3666423621007714989" class="originalNode" title="open in MPS"></a>
              </p>
            </div>
          </div>
          <p class="body">
            <b>Problem and Solution</b>&nbsp;&nbsp;Problem: How should one best proceed when creating the initial candidate arguments for the compliace with the DO-178C standard.<br/>
“What software level should be considered first?” <br/>
In favor of starting with level A is the fact that the higher the level, the more important the assurance case is; thus, articulating an explicit assurance case for level A has more value than for lower levels. In favor of starting with level D is the fact that its relatively small number of objectives simplifies the tasks of discovering and articulating the explicit case, and makes reviewing the case by others easier. By increasing the likelihood of receiving constructive feedback on the initial effort, starting with level D seems likely to provide the best chance that the final product will be of high quality. So, the answer to the question was determined to be “Level D.”<br/>
This documentation presents a detailed argument structure of the 
            Goal HLRSat
            from the 
            GSN Document Beginning_of_primary_argument_for_level_D_software
            about the software peforming the intended functions at the acceptable level of safety for level D with regards to the satisfaction of system requirements. 
          </p>
          <p class="body">
            <b>Context</b>&nbsp;&nbsp;This pattern is applicable in the context of the aviation industry, for the compliance with the Software Considerations in Airborne Systems and Equipment Certification (DO-178C) standard.
          </p>
          <p class="body">
            <b>Participants &amp; Collaborations</b>&nbsp;&nbsp;Demonstrating satisfaction of 
            Goal HLRSat
             that are imposed for level D software: showing that the high-level requirements comply with system requirements (A-3.1, 
            Goal HLRComply
            ), are accurate and consistent 
            Goal HLRAccCons
            ), and are traceable to system requirements
            Goal HLRTrace
            . In the figure, context is shown only for the definition of traceable, so as to simply presentation for this paper; but the final complete assurance case will need to include context for definitions / descriptions of comply, accurate, and consistent. According to DO-178C, the evidence for satisfaction of these three objectives is contained in the Software Verification Results.
          </p>
          <p class="body">
            <strong class="bold">Note:</strong> Pattern and information has been taken from:<br/>
Holloway, C.. “Making the Implicit Explicit: Towards an Assurance Case for DO-178C.” (2013). 
          </p>
        </div>
        <div>
          <h3 id="sid942157498040132859" class="section">1.4.3 Refinement of G3:EOCSAT</h3>
          <div class="imagecontainer border" id="sid5866579837810793272">
            <div class="imageWithBorder">
              <img src="../img/SafetyPatternsCatalogue_Refinement_of_G3_EOCSAT.png" />
            </div>
            <div class="imagecaption">
              <p class="caption">
                <b>Figure
                1.4.3-A</b><a href="http://127.0.0.1:63320/node?ref=r%3Af484f3cb-b75d-4857-b03a-36f42bd7a5b9%28_100_Patterns%29%2F3666423621007715841" class="originalNode" title="open in MPS"></a>
              </p>
            </div>
          </div>
          <p class="body">
            <b>Problem and Solution</b>&nbsp;&nbsp;Problem: How should one best proceed when creating the initial candidate arguments for the compliace with the DO-178C standard.<br/>
“What software level should be considered first?” <br/>
In favor of starting with level A is the fact that the higher the level, the more important the assurance case is; thus, articulating an explicit assurance case for level A has more value than for lower levels. In favor of starting with level D is the fact that its relatively small number of objectives simplifies the tasks of discovering and articulating the explicit case, and makes reviewing the case by others easier. By increasing the likelihood of receiving constructive feedback on the initial effort, starting with level D seems likely to provide the best chance that the final product will be of high quality. So, the answer to the question was determined to be “Level D.”<br/>
This documentation presents a detailed argument structure of the 
            Goal EOCSat
            from the 
            GSN Document Beginning_of_primary_argument_for_level_D_software
            about the software peforming the intended functions at the acceptable level of safety for level D with regards satisfaction of high-level requirements by the Software Executable Object Code. 
          </p>
          <p class="body">
            <b>Context</b>&nbsp;&nbsp;This pattern is applicable in the context of the aviation industry, for the compliance with the Software Considerations in Airborne Systems and Equipment Certification (DO-178C) standard.
          </p>
          <p class="body">
            <b>Participants &amp; Collaborations</b>&nbsp;&nbsp;The argument for satisfaction of
            Goal EOCSat
             refines into four sub-goals. Three of these sub-goals correspond to the three level D applicable objectives for testing of outputs of integration process (summarized in Table A-6); the remaining sub-goal corresponds to the only applicable objective for verification of outputs of software design process (Table A-4). All four applicable software development process (Table A-2) objectives constitute part of the relevant context for this part of the argument. One of these objectives is divided into two parts, because the portion of the objective dealing with the production of Executable Object Code (EOC) seems appropriately part of the context for G3, while the part dealing with loading of the code onto the target computer seems to be better attached to the goal concerning compatibility of EOC and target computer. The evidence for the achievement of the four sub-goals is taken from the three specific data items shown. As was the case for the G2 from 
            GSN Document Refinement_of_G2_HLRSAT
             refinement, the refinement here for 
            Goal EOCSat
             shows only some of the contextual items that will need to be included in a final, complete assurance case.
          </p>
          <p class="body">
            <strong class="bold">Note:</strong> Pattern and information has been taken from:<br/>
Holloway, C.. “Making the Implicit Explicit: Towards an Assurance Case for DO-178C.” (2013). 
          </p>
        </div>
      </div>
      <div>
        <h2 id="sid1173803721179809887" class="section">1.5 ML-specific Argument Patterns</h2>
        <div>
          <h3 id="sid6452540484739656540" class="section">1.5.1 ML Safety Assurance Scoping</h3>
          <div class="imagecontainer border" id="sid5866579837810794687">
            <div class="imageWithBorder">
              <img src="../img/SafetyPatternsCatalogue_ML_Safety_Assurance_Scoping_Argument_pattern.png" />
            </div>
            <div class="imagecaption">
              <p class="caption">
                <b>Figure
                1.5.1-A</b><a href="http://127.0.0.1:63320/node?ref=r%3Af484f3cb-b75d-4857-b03a-36f42bd7a5b9%28_100_Patterns%29%2F3735334077032860114" class="originalNode" title="open in MPS"></a>
              </p>
            </div>
          </div>
          <p class="body">
            <b>Problem &amp; Solution</b>&nbsp;&nbsp;Problem: Machine Learning (ML) is now used in a range of systems with results that are reported to exceed, under certain conditions, human performance. Establishing justified confidence in ML forms a core part of the safety case for these systems. Assurance of Machine Learning for use in Autonomous Systems (AMLAS) is a methodology which comprises a set of safety case patterns and a process for (1) systematically integrating safety assurance into the development of ML components and (2) for generating the evidence base for explicitly justifying the acceptable safety of these components when integrated into autonomous system. AMLAS scope covers the following ML lifecycle stages: ML safety assurance scoping, safety requirements elicitation, data management, model learning, model verification and model deployment. <br/>
Solution: ML safety assurance scoping and the safety requirements elicitation stages explicitly establishes the fundamental link between the system‐level hazard and risk analysis and the ML safety requirements. That is, AMLAS takes a whole system approach to ML assurance in which safety considerations are only meaningful once scoped within the wider system and operational context. In this documentation, the ML Safety Assurance Scoping pattern is presented.<br/>
<br/>
The pattern has the following objectives:<br/>
1. Define the scope of the safety assurance process for the ML component. <br/>
2. Define the scope of the safety case for the ML component.<br/>
3. Create the top‐level safety assurance claim and specify the relevant contextual information for the ML safety argument.
          </p>
          <p class="body">
            <b>Context</b>&nbsp;&nbsp;For an ML component in a particular system context, the AMLAS process supports the development of an explicit safety case for the ML component. The AMLAS process requires as input the system safety requirements generated from the system safety process. The assurance activities are performed in parallel to the development process of the ML component. Further, the AMLAS process is iterative. Each stage of the AMLAS process is linked to the ‘Feedback and Iterate’ thread and could trigger the need to reconsider information generated or consumed by other stages. This is also necessary because of the interdependencies between the different stages, e.g. an activity in one stage might use artefacts produced by another activity in a previous stage.<br/>
<br/>
AMLAS has a primary focus on off‐line supervised learning. Off‐line supervised learning, particularly applied to classification tasks, is currently the predominant application of ML for autonomous systems. Other types of ML such as reinforcement learning may also benefit from this guidance, particularly with regard to safety requirements and data management.
          </p>
          <p class="body">
            <b>Implementation (Activities) &amp; Participants &amp; Collaborations</b>&nbsp;&nbsp;This pattern is part of the AMLAS ML Assurance Scoping stage This process consists of two activities that are performed to define the safety assur‐ ance scope for an ML component. The artefacts generated from this stage are used to instantiate the ML safety assurance scoping argument pattern as part of Activity 2. An ML component comprises an ML model, e.g. a neural network, that is deployed onto the intended computing platform (i.e. comprising both hardware and software).<br/>
The AMLAS ML Assurance Scoping Process consists of the following activities: <br/>
Activity 1: Define the Safety Assurance Scope for the ML Component [E];<br/>
Activity 2: Instantiate ML Safety Assurance Scoping Argument Pattern [G];<br/>
<br/>
<strong class="bold">Inputs to the process</strong> <br/>
[A] : System Safety Requirements <br/>
[B] : Description of Operating Environment of System <br/>
[C] : System Description <br/>
[D] : ML Component Description <br/>
[F] : ML Assurance Scoping Argument Pattern<br/>
<br/>
<strong class="bold">Outputs of the process</strong><br/>
[E] : Safety Requirements Allocated to ML Component <br/>
[G] : ML Safety Assurance Scoping Argument<br/>
<br/>
Key elements from the pattern are described in this document:<br/>

            Goal G1.1
            :<br/>
The top claim in this argument pattern represents the starting point for the safety argument for the ML component by claiming that the system safety requirements that have been allocated to the compo‐ nent are satisfied in the defined environment. As such, this claim provides the link to the higher level system safety argument of which it is a part. The safety claim for the ML component is made within the context of the information that was used to establish the safety requirements allocation including the descriptions of the system and software architectures ([C]) and operational environment ([B]), and the description of the ML component ([D]). The allocated system safety requirements ([E]) are also provided as context. It is important to be able to show that the allocated safety requirements have been correctly defined, however this is part of the system safety process and is therefore outside of the scope of the ML safety assurance argument. An assumption to this effect is therefore made explicitly in this argument in 
            Assumption A1.1
            . It should be noted that to assure the validity of this assumption, a full argument and evidence regarding the system safety requirements should be provided in the safety case for the overall system. The primary aim of the ML Safety Assurance Scoping argument is to explain and justify the essential relationship between, on the one hand, the system‐level safety requirements and associ‐ ated hazards and risks, and on the other hand, the ML‐specific safety requirements and associated ML performance and failure conditions.<br/>
<br/>

            Strategy S1.1
            <br/>
The approach that is adopted to support the ML safety claim is to split the argument into two parts. Firstly the development of the ML component is considered. This argument begins through the devel‐ opment of the ML safety requirements argument as discussed in Stage 2 of the process. Secondly the deployment of the ML component is addressed. The deployment argument is considered in Stage 6 of the process. 
          </p>
          <p class="body">
            <b>Implementation</b>&nbsp;&nbsp;The instantiated ML safety assurance scoping argument and references to artefacts shall be documented for the ML component ([G]). Along with the instantiated arguments resulting from the other stages of the AMLAS process, this will constitute the safety case for the ML component.<br/>
<br/>
<strong class="bold">Possible Pitfalls/ Recommendation</strong><br/>
- The allocation of safety requirements must consider architectural features such as redundancy when allocating the safety requirements to the ML component. Where redundancy is provided by other, non‐machine‐learnt components, this may reduce the assurance burden on the ML component that should be reflected in the allocated safety requirements.<br/>
-The contribution of the human as part of the broader system should be considered. A human may provide, for example, oversight or fallback in the case of failure of the ML component. These human contributions, and any associatedhuman factors issues, e.g. automation bias [59], should be reflected when allocating safety requirements to the ML component.
          </p>
          <p class="body">
            <b>Related patterns &amp; Known uses</b>&nbsp;&nbsp;The pattern presented here is part of a document providing guidance on how to systematically integrate safety assurance into the development of ML components:<br/>
Hawkins, R., Paterson, C., Picardi, C., Jia, Y., Calinescu, R., and Habli, I., “Guidance on the Assurance of Machine Learning in Autonomous Systems (AMLAS)”, &lt;i&gt;arXiv e-prints&lt;/i&gt;, 2021.
          </p>
        </div>
        <div>
          <h3 id="sid3666423621007717891" class="section">1.5.2 ML Safety Requirements Assurance</h3>
          <div class="imagecontainer border" id="sid5866579837810794196">
            <div class="imageWithBorder">
              <img src="../img/SafetyPatternsCatalogue_Assurance_Argument_Pattern_for_ML_Safety_Requirements.png" />
            </div>
            <div class="imagecaption">
              <p class="caption">
                <b>Figure
                1.5.2-A</b><a href="http://127.0.0.1:63320/node?ref=r%3Af484f3cb-b75d-4857-b03a-36f42bd7a5b9%28_100_Patterns%29%2F4779185426163415942" class="originalNode" title="open in MPS"></a>
              </p>
            </div>
          </div>
          <p class="body">
            <b>Problem &amp; Solution</b>&nbsp;&nbsp;Problem: Machine Learning (ML) is now used in a range of systems with results that are reported to exceed, under certain conditions, human performance. Establishing justified confidence in ML forms a core part of the safety case for these systems. Assurance of Machine Learning for use in Autonomous Systems (AMLAS) is a methodology which comprises a set of safety case patterns and a process for (1) systematically integrating safety assurance into the development of ML components and (2) for generating the evidence base for explicitly justifying the acceptable safety of these components when integrated into autonomous system. AMLAS scope covers the following ML lifecycle stages: ML safety assurance scoping, safety requirements elicitation, data management, model learning, model verification and model deployment. <br/>
Solution: In this documentation, the ML Safety Requirements Assurance Pattern is presented to achieve the following objectives:<br/>
1. Develop the machine learning safety requirements from the allocated system safety requirements.<br/>
2. Validate the machine learning safety requirements against the allocated safety requirements, the system and software architecture and operational environment.<br/>
3. Create an assurance argument, based on the evidence generated by meeting the first two ob‐ jectives, that provides a clear justification for the ML safety requirements. This should explicitly explain the tradeoffs, assumptions and uncertainties concerning both the safety requirements and the process by which they are developed and validated.
          </p>
          <p class="body">
            <b>Context</b>&nbsp;&nbsp;For an ML component in a particular system context, the AMLAS process supports the development of an explicit safety case for the ML component. The AMLAS process requires as input the system safety requirements generated from the system safety process. The assurance activities are performed in parallel to the development process of the ML component. Further, the AMLAS process is iterative. Each stage of the AMLAS process is linked to the ‘Feedback and Iterate’ thread and could trigger the need to reconsider information generated or consumed by other stages. This is also necessary because of the interdependencies between the different stages, e.g. an activity in one stage might use artefacts produced by another activity in a previous stage.<br/>
<br/>
AMLAS has a primary focus on off‐line supervised learning. Off‐line supervised learning, particularly applied to classification tasks, is currently the predominant application of ML for autonomous systems. Other types of ML such as reinforcement learning may also benefit from this guidance, particularly with regard to safety requirements and data management.
          </p>
          <p class="body">
            <b>Implementation (Activities) &amp; Participants &amp; Collaborations</b>&nbsp;&nbsp;This pattern is part of the AMLAS ML Safety Requirement stage. The artefacts generated from this stage are used to instantiate the ML safety requirements assurance argument pattern as part of Activity 5. The scope of this stage is limited to the ML model, e.g. the mathematical representation of the neural network, that produces the intended output. <br/>
The AMLAS ML Safety Requirements Assurance stage consists of the following activities: <br/>
Activity 3: Develop ML Safety Requirements [H]<br/>
Activity 4: Validate ML Safety Requirements [J]<br/>
Activity 5: Instantiate ML Safety Requirements Argument Pattern [K]<br/>
<br/>
<br/>
<strong class="bold">Inputs to the process</strong> <br/>
[E] : Safety Requirements Allocated to ML Component <br/>
[I] : ML Safety Requirements Argument Pattern<br/>
<br/>
<strong class="bold">Outputs of the process</strong> <br/>
[H] : ML Safety Requirements <br/>
[J] : ML Safety Requirements Validation Results <br/>
[K] : ML Safety Requirements Argument<br/>
<br/>
Key elements from the pattern are described in this document:<br/>

            Goal G2.1
            <br/>
The top claim in this argument is that system safety requirements that have been allocated to the ML component ([E]) are satisfied by the model that is developed. This is demonstrated through considering explicit ML safety requirements defined for the ML model.<br/>
<br/>

            Strategy S2.1
            <br/>
The argument approach is a refinement strategy that justifies the translation of the allocated safety requirements into concrete ML safety requirements ([H]) as described in Activity 3. Justification J2.1 is explicitly provided to explain the issues that were involved in translating the complex real world con‐ cepts and cognitive decisions into formats that are amenable to ML implementation. This should also explain and justify the scope of the ML safety requirements and whether any of the allocated system safety requirements were not fully specified as part of the ML safety requirements. Any such allocated requirements must be addressed as part of the system safety process. For example, allocated system safety requirements with real‐time targets, which require the consideration of the performance of the underlying hardware, cannot be fully specified and tested merely by the ML model. As such these can only be meaningfully considered by also testing the integrated ML component. To sup‐ port this strategy two subclaims are provided in the argument, one demonstrating that the ML safety requirements are valid, and one concerning the satisfaction of those requirements.<br/>
<br/>

            Goal G2.3
            <br/>
The validity claim is provided to demonstrate that the ML safety requirements are a valid development of the allocated system safety requirements. Evidence from the validation results ([J]) obtained in Activity 4 is used to support the validity claim. Justification J2.2 provides rationale for the validation strategy that was adopted for Activity 4.<br/>
<br/>

            Goal G2.4
             <br/>
This claim focuses exclusively on the ML safety requirements. The claim states that the ML safety re‐<br/>
quirements are satisfied by the ML model. The claim is made in the context of the ML model ([V]) that is generated and the data ([N], [O]and [P]) that is used to create the model. Although the satisfaction of the ML safety requirements is demonstrated through verification evidence, it is also important, as for more traditional software, to provide assurance regarding the processes used for development. The ML Learning Argument Pattern ([W]) and the ML Data Argument Pattern ([R]) are therefore used to provide argument and evidence that the model (and learning process) and the data (and data management process) are sufficient. The link with assurance in these stages is established using Assurance Claim Points (ACPs) (indicated by the black squares). These represent points in the argument at which further assurance is required, focusing specifically here on how confidence in data management and model learning can be demonstrated. These ACPs can be supported through instantiation of the ML Data Argument Pattern ([W]) and the ML Data Argument Pattern ([R]) respectively.<br/>
<br/>

            Strategy S2.2
            <br/>
This is a decomposition strategy based on the different types of ML safety requirements. This will include claims regarding performance and robustness requirements, but may also include other types of ML requirements such as interpretability where these requirements are relevant to the system safety requirements. This is indicated by the ‘to be developed’ symbol, i.e. diamond, under the strategy.<br/>
<br/>

            Goal G2.4
            <br/>
This claim focuses on the ML safety requirements that consider ML performance with respect to safety‐ related outputs. The definedMLsafety requirements that relate to performance are provided as context to the claim. The argument considers each of these requirements in turn and provides a claim regarding the satisfaction of each requirement (G5.1 in the ML verification argument pattern). The satisfaction of each requirement will be demonstrated through verification activities.<br/>
<br/>

            Goal G2.5
            <br/>
This claim focuses on, and is stated in the context of, the ML safety requirements that consider ML robustness with respect to safety‐related outputs. The defined ML safety requirements that relate to robustness are provided as context to the claim. The argument considers each of these requirements in turn and provides a claim regarding the satisfaction of each requirement (G5.1 in the ML verification argument pattern [BB]). The satisfaction of each requirement will bedemonstrated through verification activities.<br/>
<br/>
<strong class="bold">Possible Pitfalls/ Recommendation</strong><br/>
- In machine learning, requirements are often seen as implicitly encoded in the data. As such, under‐specificity in requirements definition is an appealing feature. However, for rare events, such as safety incidents, this under‐specificity poses a significant assurance challenge. The de‐ velopers are still expected to assure the ability of the system to control the risk of these rare events based on concrete safety requirements against which the machine learning component is developed and tested.<br/>
- One useful approach to defining robustness requirements is to consider the dimensions of vari‐ ation which exist in the input space. These may include, for example: • variation within the domain, e.g. differences between patients of different ethnicity;<br/>
• variation due to external factors, e.g. differences due to limitations of sensing technologies or effects of environmental phenomenon<br/>
• variation based on a knowledge of the technologies used and their inherent failure modes.
          </p>
          <p class="body">
            <b>Related patterns &amp; Known uses</b>&nbsp;&nbsp;The pattern presented here is part of a document providing guidance on how to systematically integrate safety assurance into the development of ML components:<br/>
Hawkins, R., Paterson, C., Picardi, C., Jia, Y., Calinescu, R., and Habli, I., “Guidance on the Assurance of Machine Learning in Autonomous Systems (AMLAS)”, &lt;i&gt;arXiv e-prints&lt;/i&gt;, 2021.
          </p>
        </div>
        <div>
          <h3 id="sid3666423621007718360" class="section">1.5.3 Data Management</h3>
          <div class="imagecontainer border" id="sid5866579837810793869">
            <div class="imageWithBorder">
              <img src="../img/SafetyPatternsCatalogue_Assurance_Argument_Pattern_for_ML_Data.png" />
            </div>
            <div class="imagecaption">
              <p class="caption">
                <b>Figure
                1.5.3-A</b><a href="http://127.0.0.1:63320/node?ref=r%3Af484f3cb-b75d-4857-b03a-36f42bd7a5b9%28_100_Patterns%29%2F1587026482702734435" class="originalNode" title="open in MPS"></a>
              </p>
            </div>
          </div>
          <p class="body">
            <b>Problem &amp; Solution</b>&nbsp;&nbsp;Problem: Machine Learning (ML) is now used in a range of systems with results that are reported to exceed, under certain conditions, human performance. Establishing justified confidence in ML forms a core part of the safety case for these systems. Assurance of Machine Learning for use in Autonomous Systems (AMLAS) is a methodology which comprises a set of safety case patterns and a process for (1) systematically integrating safety assurance into the development of ML components and (2) for generating the evidence base for explicitly justifying the acceptable safety of these components when integrated into autonomous system. AMLAS scope covers the following ML lifecycle stages: ML safety assurance scoping, safety requirements elicitation, data management, model learning, model verification and model deployment. <br/>
Solution: In this documentation, the ML Data Management pattern is presented to achieve the following objectives:<br/>
1. Develop data requirements which are sufficient to allow for the ML safety requirements to be encoded as features against which the data sets to be produced in this stage may be assessed.<br/>
2. Generate data sets in accordance with the data requirements for use in the development and verification stages, providing a rationale for those activities undertaken with respect to the ML safety requirements.<br/>
3. Analyse the data sets obtained by objective 2 to determine their sufficiency in meeting the data requirements.<br/>
4. Create an assurance argument, based on the evidence generated by meeting the first three objec‐ tives, that provides a clear justification of the ML Data requirements. This should explicitly state the assumptions and tradeoffs made and any uncertainties concerning the data requirements and the processes by which they were developed and validated.
          </p>
          <p class="body">
            <b>Context</b>&nbsp;&nbsp;For an ML component in a particular system context, the AMLAS process supports the development of an explicit safety case for the ML component. The AMLAS process requires as input the system safety requirements generated from the system safety process. The assurance activities are performed in parallel to the development process of the ML component. Further, the AMLAS process is iterative. Each stage of the AMLAS process is linked to the ‘Feedback and Iterate’ thread and could trigger the need to reconsider information generated or consumed by other stages. This is also necessary because of the interdependencies between the different stages, e.g. an activity in one stage might use artefacts produced by another activity in a previous stage.<br/>
<br/>
AMLAS has a primary focus on off‐line supervised learning. Off‐line supervised learning, particularly applied to classification tasks, is currently the predominant application of ML for autonomous systems. Other types of ML such as reinforcement learning may also benefit from this guidance, particularly with regard to safety requirements and data management.
          </p>
          <p class="body">
            <b>Implementation (Activities) &amp; Participants &amp; Collaborations</b>&nbsp;&nbsp;This pattern is part of the AMLAS ML Data Management stage The artefacts generated from this stage are used to instantiate the ML data assurance argument pattern as part of Activity 9. <br/>
The AMLAS ML Data Management stag consists of the following activities: <br/>
Activity 6: Define Data Requirements<br/>
Activity 7: Generate ML Data [N], [O], [P]<br/>
Activity 8: Validate ML Data [S]<br/>
Activity 9: Instantiate ML Data Argument Pattern [T]: This activity requires as input the ML data argument pattern ([R]), as well as the artefacts from the previous activities of this stage ([L], [M], [N], [O], [P], [Q]and [S]). The activity uses the activities and outputs from the previous stages to create an instantiated ML data argument ([T]).<br/>
<br/>
<br/>
<strong class="bold">Inputs to this process</strong>:<br/>
[H] : ML safety requirements <br/>
[R] : ML data argument pattern<br/>
<br/>
<strong class="bold">Outputs of this process</strong> <br/>
[L] : Data requirements <br/>
[M] : Data requirements justification report <br/>
[N] : Development data <br/>
[O] : Internal test data <br/>
[P] : Verification data <br/>
[Q] : Data generation log <br/>
[S] : ML data validation results <br/>
[T] : ML data argument<br/>
<br/>
Key elements from the pattern are described in this document:<br/>

            Goal G3.1
            <br/>
The top claim in this argument pattern is that the data used during the development and verification of the ML model is sufficient. This claim is made for all three sets of data used: development, test and verification ([N], [O], [P]). The argument sets out how the sufficiency of these data sets could be demonstrated. This provides confidence in the data used, and thus increases assurance of the model itself.<br/>

            Strategy S3.1
            <br/>
The argument strategy is to argue over the defined ML data requirements which are provided as con‐ text to the argument ([L]). To support this strategy two sub‐claims are provided in the argument, one demonstrating the sufficiency of the ML data requirements, and another to demonstrate that those defined data requirements are satisfied.<br/>

            Goal G3.2
            <br/>
It is not possible to claim that the data alone can guarantee that the ML safety requirements will be satisfied, however the data used must be sufficient to enable the model that is developed to do so. This is shown by demonstrating that the requirements defined for the ML data are sufficient to ensure it is possible to create an ML model that satisfies the ML safety requirements. The ML Data Requirements Justification Report ([M]) created in Activity 4 is explicitly provided to provide evidence for this.<br/>

            Goal G3.3
            <br/>
It must be demonstrated that all of the data used throughout the lifecycle (development, test and ver‐ ification) satisfies the defined ML data requirements. This is done in the context of the decisions made during data collection to ensure the data meets the requirements. These decisions are captured and explained in the data generation log ([Q]). To showthat the data requirements are satisfied, the strategy adopted is to argue over each type of data requirement (relevance, completeness etc). The types of data requirements that have been considered should be justified. This is done explicitly in
            Justification J3.1
            . For each type of data requirements, the ML data validation results ([S]) are used as evidence that each data set meets the requirements.<br/>
<br/>
<strong class="bold">Possible Pitfalls/ Recommendation</strong><br/>
- DeepMind’s ML model for detecting acute Kidney failure reports incredible accuracy and pre‐ dictive power. However analysis [61] shows that the data used to train the model was over‐ whelmingly from male patients (93.6%). In this case an ML data requirement for balance in the gender of the data sources should have been explicitly specified since this feature is relevant to the operating context of the model (which will be used for both male and female patients). Sim‐ ilarly, the data was collected from a set of individuals that lacked other forms of diversity. This could lead to the results in operation falling far short of those promised for the affected groups of patients.<br/>
- Where existing data sources are used, a rationale should be provided in the data generation log as to how these data sources may be transferred to the current domain and any assumptions concerning relevance should be stated explicitly.<br/>
- Both financial and practical concerns can lead to data sets which are not ideal and, in such cases, clear rationale shall be provided. For example a young child crossing in front of a fast moving car may be a safety concern but gathering data for such events is not practicable.
          </p>
          <p class="body">
            <b>Related patterns &amp; Known uses</b>&nbsp;&nbsp;The pattern presented here is part of a document providing guidance on how to systematically integrate safety assurance into the development of ML components:<br/>
Hawkins, R., Paterson, C., Picardi, C., Jia, Y., Calinescu, R., and Habli, I., “Guidance on the Assurance of Machine Learning in Autonomous Systems (AMLAS)”, &lt;i&gt;arXiv e-prints&lt;/i&gt;, 2021.
          </p>
        </div>
        <div>
          <h3 id="sid3666423621007718644" class="section">1.5.4 Model Learning</h3>
          <div class="imagecontainer border" id="sid5866579837810794536">
            <div class="imageWithBorder">
              <img src="../img/SafetyPatternsCatalogue_ML_Model_Learning_Argument_Pattern.png" />
            </div>
            <div class="imagecaption">
              <p class="caption">
                <b>Figure
                1.5.4-A</b><a href="http://127.0.0.1:63320/node?ref=r%3Af484f3cb-b75d-4857-b03a-36f42bd7a5b9%28_100_Patterns%29%2F2254327181659910900" class="originalNode" title="open in MPS"></a>
              </p>
            </div>
          </div>
          <p class="body">
            <b>Problem &amp; Solution</b>&nbsp;&nbsp;Problem: Machine Learning (ML) is now used in a range of systems with results that are reported to exceed, under certain conditions, human performance. Establishing justified confidence in ML forms a core part of the safety case for these systems. Assurance of Machine Learning for use in Autonomous Systems (AMLAS) is a methodology which comprises a set of safety case patterns and a process for (1) systematically integrating safety assurance into the development of ML components and (2) for generating the evidence base for explicitly justifying the acceptable safety of these components when integrated into autonomous system. AMLAS scope covers the following ML lifecycle stages: ML safety assurance scoping, safety requirements elicitation, data management, model learning, model verification and model deployment. <br/>
Solution: In this documentation, the Model Learning Pattern is presented to achieve the following objectives:<br/>
1. Develop the machine learnt model using the development data obtained in the previous stage such that the allocated ML safety requirements are satisfied.<br/>
2. Use internal test data to assess the extent to which the machine learnt model is able to meet the ML safety requirements when presented with data not used for development.<br/>
3. Create an assurance argument, based on the evidence generated by meeting the first two objec‐ tives, which provides a clear justification that the ML model meets the ML safety requirements. This should explicitly explain the tradeoffs, assumptions and uncertainties concerning both the ML model and the process by which it is developed and validated.
          </p>
          <p class="body">
            <b>Context</b>&nbsp;&nbsp;For an ML component in a particular system context, the AMLAS process supports the development of an explicit safety case for the ML component. The AMLAS process requires as input the system safety requirements generated from the system safety process. The assurance activities are performed in parallel to the development process of the ML component. Further, the AMLAS process is iterative. Each stage of the AMLAS process is linked to the ‘Feedback and Iterate’ thread and could trigger the need to reconsider information generated or consumed by other stages. This is also necessary because of the interdependencies between the different stages, e.g. an activity in one stage might use artefacts produced by another activity in a previous stage.<br/>
<br/>
AMLAS has a primary focus on off‐line supervised learning. Off‐line supervised learning, particularly applied to classification tasks, is currently the predominant application of ML for autonomous systems. Other types of ML such as reinforcement learning may also benefit from this guidance, particularly with regard to safety requirements and data management.
          </p>
          <p class="body">
            <b>Implementation (Activities) &amp; Participants &amp; Collaborations</b>&nbsp;&nbsp;This pattern is part of the AMLAS ML Model Learning Stage. This stage consists of three activities. The artefacts generated from this stage are used to instantiate the ML model assurance argument pattern as part of Activity 12. <br/>
The AMLAS ML Model Learning Stage consists of the following activities: <br/>
Activity 10: Create ML Model [V]<br/>
Activity 11: Test ML Model [V]<br/>
Activity 12: Instantiate ML Learning Argument Pattern [Y] This<br/>
<br/>
<strong class="bold">Inputs to this process</strong>:<br/>
[H] : ML Safety Requirements <br/>
[N] : Development Data <br/>
[O] : Internal Test Data <br/>
[W] : ML Learning Argument Pattern<br/>
<br/>
<strong class="bold">Outputs of this process</strong><br/>
[V] : ML Model <br/>
[X] : Internal Test Results <br/>
[Y] : ML Learning Argument <br/>
[U] : Model Development Log<br/>
<br/>
Key elements from the pattern are described in this document:<br/>

            Goal G4.1
            <br/>
The top claim in this argument pattern is that the development of the learnt model ([V]) is sufficient. The sufficiency of the model learning process is argued through considering the appropriateness of the model development activities undertaken.<br/>

            Strategy S4.1
            <br/>
The argument strategy is to argue over the internal testing of the model performed during development as well as the development approach adopted. The appropriateness of the development activities is considered within the context of creating a model that both satisfies the ML safety requirements as well as meeting the additional constraints that are imposed on the model, such as performance and cost.<br/>

            Goal G4.2
            <br/>
It must be demonstrated that the ML model that is selected satisfies the ML safety requirements. This is shown by using the internal test data ([O]) generated from Activity 7. The model must be shown to satisfy the ML safety requirements when this test data is applied. The internal testing claim is supported through evidence from the internal test results ([X]).<br/>
A justification must be provided that the results obtained from the internal testing are sufficient to indicate that the ML safety requirements are satisfied. This justification is provided in
            Justification J4.1
            <br/>

            Goal G4.3
             This claim considers the approach that has been adopted in developing the model. This claim is sup‐ ported by claims regarding the type of model selected, the model parameters that are used and the process that is applied. <br/>

            Goal G4.5
            <br/>
It must be demonstrated that the type of model that is created in Activity 5 is appropriate for the given set of ML safety requirements and the other model constraints. The evidence for the type of model selected is captured in the model development log ([U]), which is used as evidence to support this claim.<br/>

            Goal G4.6
            <br/>
 It must be demonstrated that the parameters of the selected model have been appropriately tuned in<br/>
Activity 5. The parameters must be shown to be appropriate for the given set of ML safety require‐ ments. The rationale for how the model parameters are determined should be captured in the model development log ([U]), which is used as evidence to support this claim.<br/>

            Goal G4.7
            <br/>
It must be demonstrated that the process is appropriate. As discussed in Activity 5, this will be a highly iterative process involving a number of decisions on each iteration, and the development of multiple models. The process will also involve decisions regarding the model architecture. The rationale for the process decisions should be included in the model development log ([U]) along with a justification for the appropriateness of the development tool chain used.<br/>
<br/>
<strong class="bold">Possible Pitfalls/ Recommendation</strong><br/>
- To ensure that the simplest model possible to meet the safety requirements was selected, reg‐ ularisation is employed, adding a cost to the loss function to penalise the number of neurons in the model.<br/>
- The model development log may include details of model selection, changes to hyperparameters or changes to trade‐off threshold definitions etc. For example “the threshold level for classifica‐ tion was set to x to ensure that the number of false positives identified in the development data was less than y”. This information could aid developers when trying to develop a model which achieves acceptable false positive rates.<br/>
-In creating an acceptable model it is important to note that it is not only the performance of the model that matters. It is important to consider trade‐offs between different properties such as trade‐offs between cost of hardware and performance, performance and robustness or sensitiv‐ ity and specificity. Several measures are available to assess some of these trade‐offs. For exam‐ ple the Area Under ROC Curves enable the trade‐offs between false‐positive and false‐negative classifications to be evaluated [20].<br/>
- A common problem that is encountered when creating a model is overfitting to training data. This happens when the model performs well using the development data but poorly when pre‐ sented with data not seen before. This results from creating a model that focuses on maximising its performance for the data available, but whose performance does not generalise. Techniques such as cross‐validation [2], leave‐one‐out [14] and early stopping [54] can be used in handling the development data during the creation of the model in order to improve its generalisability and thus its ability to satisfy the ML safety requirements.
          </p>
          <p class="body">
            <b>Related patterns &amp; Known uses</b>&nbsp;&nbsp;The pattern presented here is part of a document providing guidance on how to systematically integrate safety assurance into the development of ML components:<br/>
Hawkins, R., Paterson, C., Picardi, C., Jia, Y., Calinescu, R., and Habli, I., “Guidance on the Assurance of Machine Learning in Autonomous Systems (AMLAS)”, &lt;i&gt;arXiv e-prints&lt;/i&gt;, 2021.
          </p>
        </div>
        <div>
          <h3 id="sid3666423621007719155" class="section">1.5.5 ML Verification pattern</h3>
          <div class="imagecontainer border" id="sid5866579837810794359">
            <div class="imageWithBorder">
              <img src="../img/SafetyPatternsCatalogue_Assurance_Argument_Pattern_For_ML_Verification.png" />
            </div>
            <div class="imagecaption">
              <p class="caption">
                <b>Figure
                1.5.5-A</b><a href="http://127.0.0.1:63320/node?ref=r%3Af484f3cb-b75d-4857-b03a-36f42bd7a5b9%28_100_Patterns%29%2F3655119823681662520" class="originalNode" title="open in MPS"></a>
              </p>
            </div>
          </div>
          <p class="body">
            <b>Problem &amp; Solution</b>&nbsp;&nbsp;Problem: Machine Learning (ML) is now used in a range of systems with results that are reported to exceed, under certain conditions, human performance. Establishing justified confidence in ML forms a core part of the safety case for these systems. Assurance of Machine Learning for use in Autonomous Systems (AMLAS) is a methodology which comprises a set of safety case patterns and a process for (1) systematically integrating safety assurance into the development of ML components and (2) for generating the evidence base for explicitly justifying the acceptable safety of these components when integrated into autonomous system. AMLAS scope covers the following ML lifecycle stages: ML safety assurance scoping, safety requirements elicitation, data management, model learning, model verification and model deployment. <br/>
Solution: In this documentation, the ML Verification Pattern is presented to achieve the following objectives:<br/>
1. Demonstrate that the model will meet the ML safety requirements when exposed to inputs not present during the development of the model.<br/>
2. Create an assurance argument, based on the evidence generated by the first objective. The ar‐ gument should clearly demonstrate the relationship between the verification evidence and the ML safety requirements. It should explicitly explain the tradeoffs, assumptions and uncertainties concerning the verification results and the process by which they were generated.
          </p>
          <p class="body">
            <b>Context</b>&nbsp;&nbsp;For an ML component in a particular system context, the AMLAS process supports the development of an explicit safety case for the ML component. The AMLAS process requires as input the system safety requirements generated from the system safety process. The assurance activities are performed in parallel to the development process of the ML component. Further, the AMLAS process is iterative. Each stage of the AMLAS process is linked to the ‘Feedback and Iterate’ thread and could trigger the need to reconsider information generated or consumed by other stages. This is also necessary because of the interdependencies between the different stages, e.g. an activity in one stage might use artefacts produced by another activity in a previous stage.<br/>
<br/>
AMLAS has a primary focus on off‐line supervised learning. Off‐line supervised learning, particularly applied to classification tasks, is currently the predominant application of ML for autonomous systems. Other types of ML such as reinforcement learning may also benefit from this guidance, particularly with regard to safety requirements and data management.
          </p>
          <p class="body">
            <b>Implementation (Activities) &amp; Participants &amp; Collaborations</b>&nbsp;&nbsp;This pattern is part of the AMLAS ML Model Learning Stage. This stage consists of two activities that are performed to provide assurance in the ML Model verification process. The primary artefacts generated from this stage are ML model veri‐ fication results which are used to instantiate the ML verification argument pattern as part of Activity 14.<br/>
The AMLAS ML Verification Stage consists of the following activities: <br/>
Activity 13: Verify ML Model<br/>
Activity 14: Instantiate ML Verification Argument Pattern [CC]<br/>
<br/>
<strong class="bold">Inputs to this process</strong>:<br/>
[H] : ML safety requirements <br/>
[P] : Verification data <br/>
[V] : ML Model<br/>
[BB] : ML verification argument pattern<br/>
<br/>
<strong class="bold">Outputs of this process</strong><br/>
[Z] : ML verification results<br/>
[AA] : Verification log <br/>
[CC] : ML Verification argument<br/>
<br/>
Key elements from the pattern are described in this document:<br/>

            Goal G5.1
            <br/>
 The top claim in the verification argument pattern corresponds to the bottom claim in the safety re‐<br/>
quirements argument pattern ([I]); it is at this point that each ML safety requirement that has been established must be shown to be met. The satisfaction of the requirement is shown through the verification activities that are performed, as discussed in Activity 6 from 
            GSN Document Assurance_Argument_Pattern_for_ML_Data
            . This claim is supported by strategy 
            Strategy S5.1
             that reasons about the verification activities undertaken and a claim 
            Goal G5.2
            , that provides evidence from the Verification log ([AA]) that the verification activities have been performed independently from the development of the ML model.<br/>

            Strategy S5.1
            <br/>
In order to demonstrate that the ML safety requirement is sufficiently satisfied, the pattern provides a choice over how the claim can be supported. The evidence may come, as discussed in Activity 6, from any combination of testing and formal verification. The choice in the argument should be interpreted as “at‐least‐1”, allowing for multiple legs of argumentation. The combination of verification approaches used should be justified in 
            Justification J5.1
            . The “requires development” adornment to strategy 
            Strategy S5.1
             indicates that other verification approaches may optionally also be adopted where this is felt to be required. An argument and evidence regarding any such approaches must be included in the assurance argument.<br/>

            Goal G5.3
            <br/>
When the verification strategy includes test‐based verification, it must be demonstrated that the ML model satisfies the ML safety requirement when the verification data is applied. The testing claim is supported through evidence from the test results ([Z]). For any ML safety requirement, the test data used will be a subset of the verification data samples ([P]) generated from Activity 7 from 
            GSN Document Assurance_Argument_Pattern_for_ML_Data
            . The test data must demonstrate that the ML safety requirement is satisfied across a sufficient range of inputs representing the operating environment, that are not included in the data used in the model learning stage. The suf‐ ficiency of the test data is justified in the verification log ([AA]). It is also necessary to consider the way in which the test results were obtained. This is particularly important where testing is not performed on the target system. This is considered in 
            Goal G5.6
             where evidence must be provided to demonstrate that the test platform and test environment used to carry out the verification testing is sufficiently repre‐ sentative of the operational platform of the system to which the ML component will be deployed. G5.6 is not developed further as part of this guidance.<br/>

            Goal Goal 5.4
            <br/>
When the verification strategy includes formal verification, a claim is made that the ML model satisfies formally specified properties. The formally specified properties should be a sufficient formal repre‐ sentation of the intent of the ML safety requirement that is being verified. A justification should be provided in 
            Justification J5.2
             to explain the sufficiency of the translation from the ML safety requirement to the for‐ mally specified properties. The formal verification claim is supported through evidence from the formal verification results ([Z]). For those results to be valid, it must be demonstrated that the formal model created to perform the verification is sufficiently representative of the behaviour of the learnt model, and that all assumptions made as part of the verification about the system and operating environment are valid. This argument is made under 
            Goal G5.8
            , which is not developed further as part of this guidance.<br/>
<br/>
<strong class="bold">Possible Pitfalls/ Recommendation</strong><br/>
- The ML verification results should evaluate test completeness with respect to the dimensions of variability outlined in the ML safety requirements. This is directly related to the desire for data completeness outlined in Stage 3 of the process.<br/>
- It is important to ensure that the verification data is not made available to the development team since if they are to have oversight of the verification data this is likely to lead to techniques at de‐ velopment time which circumvent specific samples in the verification set rather than considering the problem of generalisation more widely<br/>
- Independence should be proportionate to the criticality of the ML model. In addition to different degrees of independence between the development and verification data sets e.g. data sets compiled from one or more hospitals, further independence may be necessary between the development and verification engineers at the team or organisational levels.
          </p>
          <p class="body">
            <b>Related patterns &amp; Known uses</b>&nbsp;&nbsp;The pattern presented here is part of a document providing guidance on how to systematically integrate safety assurance into the development of ML components:<br/>
Hawkins, R., Paterson, C., Picardi, C., Jia, Y., Calinescu, R., and Habli, I., “Guidance on the Assurance of Machine Learning in Autonomous Systems (AMLAS)”, &lt;i&gt;arXiv e-prints&lt;/i&gt;, 2021.
          </p>
        </div>
        <div>
          <h3 id="sid3666423621007719661" class="section">1.5.6 ML Model Deployment Pattern</h3>
          <div class="imagecontainer border" id="sid5866579837810794022">
            <div class="imageWithBorder">
              <img src="../img/SafetyPatternsCatalogue_Assurance_Argument_Pattern_for_ML_Model_Deployment.png" />
            </div>
            <div class="imagecaption">
              <p class="caption">
                <b>Figure
                1.5.6-A</b><a href="http://127.0.0.1:63320/node?ref=r%3Af484f3cb-b75d-4857-b03a-36f42bd7a5b9%28_100_Patterns%29%2F4880846701282583887" class="originalNode" title="open in MPS"></a>
              </p>
            </div>
          </div>
          <p class="body">
            <b>Problem &amp; Solution</b>&nbsp;&nbsp;Problem: Machine Learning (ML) is now used in a range of systems with results that are reported to exceed, under certain conditions, human performance. Establishing justified confidence in ML forms a core part of the safety case for these systems. Assurance of Machine Learning for use in Autonomous Systems (AMLAS) is a methodology which comprises a set of safety case patterns and a process for (1) systematically integrating safety assurance into the development of ML components and (2) for generating the evidence base for explicitly justifying the acceptable safety of these components when integrated into autonomous system. AMLAS scope covers the following ML lifecycle stages: ML safety assurance scoping, safety requirements elicitation, data management, model learning, model verification and model deployment. <br/>
Solution: In this documentation, the ML Model Deployment Pattern is presented to achieve the following objectives:<br/>
1. Integrate the machine learnt component into the target system in such a manner that the system satisfies the allocated system safety requirements. The component should be integrated in the pipeline linking its inputs and outputs to other system components.<br/>
2. Demonstrate that the allocated system safety requirements are still satisfied during operation of the target system and environment.<br/>
3. Create an assurance argument to demonstrate that the ML model will continue to meet the ML safety requirements once integrated into the target system.<br/>

          </p>
          <p class="body">
            <b>Context</b>&nbsp;&nbsp;For an ML component in a particular system context, the AMLAS process supports the development of an explicit safety case for the ML component. The AMLAS process requires as input the system safety requirements generated from the system safety process. The assurance activities are performed in parallel to the development process of the ML component. Further, the AMLAS process is iterative. Each stage of the AMLAS process is linked to the ‘Feedback and Iterate’ thread and could trigger the need to reconsider information generated or consumed by other stages. This is also necessary because of the interdependencies between the different stages, e.g. an activity in one stage might use artefacts produced by another activity in a previous stage.<br/>
<br/>
AMLAS has a primary focus on off‐line supervised learning. Off‐line supervised learning, particularly applied to classification tasks, is currently the predominant application of ML for autonomous systems. Other types of ML such as reinforcement learning may also benefit from this guidance, particularly with regard to safety requirements and data management.
          </p>
          <p class="body">
            <b>Implementation (Activities) &amp; Participants &amp; Collaborations</b>&nbsp;&nbsp;This pattern is part of the AMLAS ML Model Learning Stage. This stage consists of three activities that provide a basis for ML component deployment assurance. This process shall be followed not only for initial deployment of the compo‐ nent but also for any subsequent deployment required to update the component within the system. The artefacts generated from this stage are used to instantiate the ML model deployment assurance argument pattern as part of Activity 17.<br/>
The AMLAS ML Model Deployment Stage consists of the following activities: <br/>
Activity 15: Integrate ML Model<br/>
Activity 16: Test the Integration [FF]<br/>
Activity 17: Instantiate ML Deployment Argument Pattern [HH]<br/>
<br/>
<strong class="bold">Inputs to this process</strong>:<br/>
[A] : System Safety Requirements <br/>
[B] : Environment Description <br/>
[C] : System Description <br/>
[V] : ML Model<br/>
[GG] : ML Deployment Argument Pattern <br/>
[EE] : Operational scenarios<br/>
<br/>
<strong class="bold">Outputs of this process</strong><br/>
[DD] : Erroneous Behaviour Log <br/>
[FF] : Integration Testing Results <br/>
[HH] : ML Deployment Argument<br/>
<br/>
Key elements from the pattern are described in this document:<br/>
 
            Goal G6.1
            <br/>
It must be demonstrated that the safety requirements allocated to theML component are still met when the ML component is deployed to the system in which it operates. This is shown by providing two sub‐ claims. Firstly, the ML component integration claim demonstrates that the safety requirements (that were satisfied by the ML model) are also met when the ML component is integrated into the rest of the system. Secondly, the ML component operation claim is provided to show that the safety requirements will continue to be met throughout the operation of the system.<br/>

            Goal G6.2
            <br/>
It must be demonstrated that the safety requirements allocated to the ML component are satisfied when the component is integrated to the system. To demonstrate this, the ML component must be executed as part of the system following integration. It must be checked that the safety requirements are satisfied when the defined set of operating scenarios are executed. The operating scenarios used in the integration testing ([FF]) are provided as context for the claim. The sufficiency of the operating scenarios that are used must be justified in 
            Justification J6.1
            . This justification explains how the scenarios were identified such that they represent real scenarios of interest that may be encountered when the system is in operation.<br/>

            Strategy S6.2
            <br/>
The strategy to support the integration claim is to firstly use the integration test results ([FF]) to demon‐ strate the safety requirements are met for the defined operating scenarios. Integration testing is often performed for autonomous systems using a simulator. Where this is the case it is also necessary to demonstrate that the simulations that are used are a sufficient representation of the operational sys‐ tem to which the ML component is deployed. Evidence for this will be provided to support claim 
            Goal G6.5
            .<br/>

            Goal G6.3
            <br/>
It must also be demonstrated that the safety requirements allocated to the ML component continue to be satisfied during the operation of the system. To demonstrate this, claim G6.6 shows that the system is designed such that it supports the safe operation of the ML component, and 
            Goal G6.7
             demonstrates that the observed behaviour during operation continues to satisfy the safety requirements. In a complete safety case for an ML component argument and evidence to support this claim would be required.<br/>

            Goal G6.6
            <br/>
It must be demonstrated that the design of the system into which the ML component is integrated is robust by taking account of the identified potential erroneous behaviour ([DD]). It must be shown that predicted erroneous behaviour will not result in violation of the safety requirements. In particu‐ lar the argument must focus on erroneous inputs to the ML component from the rest of the system and erroneous outputs from the ML component itself. The argument must also consider assumptions made about the system and the operating environment during the development of the ML component that may become invalid during operation. The sufficiency of the identification of these erroneous behaviours must be justified in 
            Justification J6.2
            . This may be informed by the results of system safety analysis activities. Claim 
            Goal G6.6
             is supported by two sub‐claims, one that demonstrates the system design incorporates sufficient monitoring of erroneous behaviours, and one demonstrating that the response of the system to such behaviours is acceptable.<br/>

            Goal G6.8
            <br/>
It must be demonstrated that the system design incorporates sufficient monitoring of the identified erroneous behaviour to ensure that any behaviour that could result in violation of a safety requirement will be identified if it occurs during operation.<br/>

            Goal G6.9
            <br/>
It must be demonstrated that the system design ensures that an acceptable response can be provided if monitoring reveals erroneous behaviour during operation. The responsemay takemany forms, depending on the nature of the system, the relevant system hazard behaviour and the erroneous behaviour identified. This may include, for example, the provision of redundancy in the system architecture or the specification of safe degraded operation. Evidence should be provided to show that a sufficiently safe response is provided.<br/>
<br/>
<strong class="bold">Possible Pitfalls/ Recommendation</strong><br/>
- It may be possible to create a complex deep neural network that provides excellent performance. However such a model might require large computational power to execute. If the hardware in which the model will be deployed does not have sufficient computational power then a different model may need to be created in order to reduce the required computational power.<br/>
- It is important to evaluate latency associated with accessing input data. Relying on sensing data from other systems, via external networks, may unacceptably slow down the output of the ML component.
          </p>
          <p class="body">
            <b>Related patterns &amp; Known uses</b>&nbsp;&nbsp;The pattern presented here is part of a document providing guidance on how to systematically integrate safety assurance into the development of ML components:<br/>
Hawkins, R., Paterson, C., Picardi, C., Jia, Y., Calinescu, R., and Habli, I., “Guidance on the Assurance of Machine Learning in Autonomous Systems (AMLAS)”, &lt;i&gt;arXiv e-prints&lt;/i&gt;, 2021.
          </p>
        </div>
      </div>
      <div>
        <h2 id="sid1173803721179809940" class="section">1.6 DO-178C-Specific Argument Patterns</h2>
        <div>
          <h3 id="sid1941327365747442494" class="section">1.6.1 Beginning of primary argument for level D software</h3>
          <div class="imagecontainer border" id="sid5866579837810794787">
            <div class="imageWithBorder">
              <img src="../img/SafetyPatternsCatalogue_Beginning_of_primary_argument_for_level_D_software.png" />
            </div>
            <div class="imagecaption">
              <p class="caption">
                <b>Figure
                1.6.1-A</b><a href="http://127.0.0.1:63320/node?ref=r%3Af484f3cb-b75d-4857-b03a-36f42bd7a5b9%28_100_Patterns%29%2F3666423621007713838" class="originalNode" title="open in MPS"></a>
              </p>
            </div>
          </div>
          <p class="body">
            <b>Problem and Solution</b>&nbsp;&nbsp;Problem: How should one best proceed when creating the initial candidate arguments for the compliace with the DO-178C standard.<br/>
“What software level should be considered first?” <br/>
In favor of starting with level A is the fact that the higher the level, the more important the assurance case is; thus, articulating an explicit assurance case for level A has more value than for lower levels. In favor of starting with level D is the fact that its relatively small number of objectives simplifies the tasks of discovering and articulating the explicit case, and makes reviewing the case by others easier. By increasing the likelihood of receiving constructive feedback on the initial effort, starting with level D seems likely to provide the best chance that the final product will be of high quality. So, the answer to the question was determined to be “Level D.”<br/>
This documentation presents an argument fragment about the software peforming the intended functions at the acceptable level of safety for level D.
          </p>
          <p class="body">
            <b>Context</b>&nbsp;&nbsp;This pattern is applicable in the context of the aviation industry, for the compliance with the Software Considerations in Airborne Systems and Equipment Certification (DO-178C) standard.
          </p>
          <p class="body">
            <b>Participants &amp; Collaborations</b>&nbsp;&nbsp;The overall 
            Goal SwAcc
            is derived from the stated purpose of DO-178C, modified for the software level. Acceptable level of safety for level D is derived from the stated purpose of DO-178C, modified for the software level. Three items of context are identified as necessary for this goal to make sense: a description of the software’s intended function (
            Context IntFun
            ), the definition of software level D (
            Context SwLevelD
            ), and the relevant parts of the airworthiness requirements that define what constitutes an acceptable level of safety
            Context AwReg
            . Only the definition of software level D (
            Context SwLevelD
            )is provided directly in DO-178C; the others are external to the document. A critical assumption on which the entire argument rests is that the assignment of level D to the software is correct.<br/>
The DO-178C objectives and activities for Level D software imply that the implicit argument for the top-level 
            Goal SwAcc
             is based on showing that the software is correct relative to the allocated system requirements. This implicit argument relies for its cogency on <br/>
(a) the assumption that the allocated system requirements are valid and sufficient with respect to the software’s intended function; and <br/>
(b) the justification discussed in the previous section explaining the relationship between correctness and safety in the presence of valid and sufficient requirements.<br/>

          </p>
          <p class="body">
            <b>Implementation</b>&nbsp;&nbsp;For Level D software, arguing by correctness involves two sub-goals: 
            Goal HLRSat
             and 
            Goal EOCSat
            . The former involves showing an appropriate relationship between the developed high-level requirements and the system requirements; the latter involves showing that the developed executable object code implements the high-level requirements. Both of these goals have meaning only within the context of high-level requirements being developed (which is DO-178C objective A-2.1), and any derived high-level requirements being provided to the system processes, including the system safety assessment processes (A-2.2). 
            GSN Document Refinement_of_G2_HLRSAT
            and 
            GSN Document Refinement_of_G3_EOCSAT
             show further refinements of G2 and G3 respectively.
          </p>
          <p class="body">
            <strong class="bold">Note:</strong> Pattern and information has been taken from:<br/>
Holloway, C.. “Making the Implicit Explicit: Towards an Assurance Case for DO-178C.” (2013). 
          </p>
        </div>
      </div>
      <div>
        <h2 id="sid3859986046039745643" class="section">1.7 Confidence Argument Patterns</h2>
        <div>
          <h3 id="sid2186533634770907594" class="section">1.7.1 Confidence argument structure for an asserted inference</h3>
          <div class="imagecontainer border" id="sid5866579837810794935">
            <div class="imageWithBorder">
              <img src="../img/SafetyPatternsCatalogue_Confidence_Argument_Structure_For_An_Asserted_Inference.png" />
            </div>
            <div class="imagecaption">
              <p class="caption">
                <b>Figure
                1.7.1-A</b><a href="http://127.0.0.1:63320/node?ref=r%3Af484f3cb-b75d-4857-b03a-36f42bd7a5b9%28_100_Patterns%29%2F3317245738482614227" class="originalNode" title="open in MPS"></a>
              </p>
            </div>
          </div>
          <p class="body">
            <b>Problem and Solution</b>&nbsp;&nbsp;<br/>
Arguments that do not distinguish between the arguments of safety and confidence might lead to:<br/>
- voluminous, rambling, ad infinitum arguments;<br/>
- poorly documented safety argument and the confidence argument, because the lack of distinction between the two makes it more difficult to spot incompleteness or poor structure in either;<br/>
- necessary elements of the argument being sometimes omitted, because the need for the specific elements is lost in the volume of the argument;<br/>
- arguments becoming indirect and unfocused, and the link between elements of the argument and risk is often lost;<br/>
- unnecessary material bein sometimes included in arguments without proper con- sideration or explanation of its relevance – ‘just in case’;<br/>
- arguments becoming difficult to build, and weaknesses of the argument are sometimes not evident and so are easily overlooked;<br/>
- arguments becoming difficult to review because of the size and lack of focus;<br/>
Separation of the safety and confidence arguments offers the opportunity to<br/>
mitigate these difficulties by providing different foci for safety and confidence. In addition, careful attention to linking the two arguments provides a mechanism for guiding analysis of the interrelationship between safety and confidence;<br/>
<br/>
To gain assurance in the argumentation, the sub-claims put forward to implement the chosen argument strategy need to be, if true, a sufficient basis upon which to infer the conclusion stated in the parent claim.<br/>
It is necessary to provide a confidence argument that demonstrates why the asserted in- ference should be believed. The ACP for an asserted inference is the link between the parent claim and its strategy or sub-claims.<br/>
<br/>
This pattern demonstrates that there is sufficient confidence in the asserted inference by including a sub-argument:<br/>
- that the asserted inference is true <br/>
- that the assurance deficits relating to the asserted inference have been identified <br/>
- that any residual assurance deficits are acceptable.
          </p>
          <p class="body">
            <b>Context</b>&nbsp;&nbsp;Contexts in which a separate structure is needed to explicitly manage the assurance deficit such that the overall confidence is considered acceptable.
          </p>
          <p class="body">
            <b>Participants &amp; Collaborations</b>&nbsp;&nbsp;The strategy used in the third sub-argument is to argue over the set of assurance deficits, and for each to show:<br/>
- the existence of significant counter evidence associated with the subject assur- ance deficit is considered unlikely<br/>
- the sensitivity of the remainder of the argument to the subject assurance deficit is acceptably low, i.e., the assurance deficit may be justified as acceptable when considered in the context of the other arguments and evidence in the safety case.<br/>

          </p>
          <p class="body">
            <b>Related patterns &amp; Known Uses</b>&nbsp;&nbsp;An example of how this pattern may be instantiated is included in:<br/>
- Hawkins R., Kelly T., Knight J., Graydon P. (2011) A New Approach to creating Clear Safety Arguments. In: Dale C., Anderson T. (eds) Advances in Systems Safety. Springer, London. https://doi.org/10.1007/978-0-85729-133-2_1
          </p>
          <p class="body">
            <strong class="bold">Note</strong>: Documentation provided from the following publication:<br/>
Hawkins R., Kelly T., Knight J., Graydon P. (2011) A New Approach to creating Clear Safety Arguments. In: Dale C., Anderson T. (eds) Advances in Systems Safety. Springer, London. https://doi.org/10.1007/978-0-85729-133-2_1
          </p>
        </div>
        <div>
          <h3 id="sid2186533634770908135" class="section">1.7.2 Confidence argument structure for an asserted solution</h3>
          <div class="imagecontainer border" id="sid5866579837810795101">
            <div class="imageWithBorder">
              <img src="../img/SafetyPatternsCatalogue_Confidence_Argument_Structure_For_An_Asserted_Solution.png" />
            </div>
            <div class="imagecaption">
              <p class="caption">
                <b>Figure
                1.7.2-A</b><a href="http://127.0.0.1:63320/node?ref=r%3Af484f3cb-b75d-4857-b03a-36f42bd7a5b9%28_100_Patterns%29%2F7846346562839984545" class="originalNode" title="open in MPS"></a>
              </p>
            </div>
          </div>
          <p class="body">
            <b>Problem and Solution</b>&nbsp;&nbsp;<br/>
Arguments that do not distinguish between the arguments of safety and confidence might lead to:<br/>
- voluminous, rambling, ad infinitum arguments;<br/>
- poorly documented safety argument and the confidence argument, because the lack of distinction between the two makes it more difficult to spot incompleteness or poor structure in either;<br/>
- necessary elements of the argument being sometimes omitted, because the need for the specific elements is lost in the volume of the argument;<br/>
- arguments becoming indirect and unfocused, and the link between elements of the argument and risk is often lost;<br/>
- unnecessary material bein sometimes included in arguments without proper con- sideration or explanation of its relevance – ‘just in case’;<br/>
- arguments becoming difficult to build, and weaknesses of the argument are sometimes not evident and so are easily overlooked;<br/>
- arguments becoming difficult to review because of the size and lack of focus;<br/>
Separation of the safety and confidence arguments offers the opportunity to<br/>
mitigate these difficulties by providing different foci for safety and confidence. In addition, careful attention to linking the two arguments provides a mechanism for guiding analysis of the interrelationship between safety and confidence;<br/>
<br/>
To gain assurance in the argumentation, the sub-claims put forward to implement the chosen argument strategy need to be, if true, a sufficient basis upon which to infer the conclusion stated in the parent claim.<br/>
It is necessary to provide a confidence argument that demonstrates why the asserted in- ference should be believed. The ACP for an asserted inference is the link between the parent claim and its strategy or sub-claims.<br/>
<br/>
The pattern demonstrates that there is sufficient confidence in the asserted solution by including a sub-argument that:<br/>
- the asserted solution is trustworthy <br/>
- use of the asserted solution is appropriate.
          </p>
          <p class="body">
            <b>Context</b>&nbsp;&nbsp;Contexts in which it is needed to argue the confidence in the gathered evidence and in cases where a separate structure is needed to explicitly manage the assurance deficit such that the overall confidence is considered acceptable.
          </p>
          <p class="body">
            <b>Implementation</b>&nbsp;&nbsp;<br/>
The claims regarding the acceptability of the residual assurance deficits in each case (CC13 and CC23) would be supported using the same pattern as provided under CC3 in the following documentation: Confidence_Argument_Structure_For_An_Asserted_Inference_Doc
          </p>
          <p class="body">
            <b>Related patterns &amp; Known Uses</b>&nbsp;&nbsp;An example of how this pattern may be instantiated is included in:<br/>
- Hawkins R., Kelly T., Knight J., Graydon P. (2011) A New Approach to creating Clear Safety Arguments. In: Dale C., Anderson T. (eds) Advances in Systems Safety. Springer, London. https://doi.org/10.1007/978-0-85729-133-2_1
          </p>
          <p class="body">
            <strong class="bold">Note</strong>: Documentation provided from the following publication:<br/>
Hawkins R., Kelly T., Knight J., Graydon P. (2011) A New Approach to creating Clear Safety Arguments. In: Dale C., Anderson T. (eds) Advances in Systems Safety. Springer, London. https://doi.org/10.1007/978-0-85729-133-2_1
          </p>
        </div>
        <div>
          <h3 id="sid2186533634773199179" class="section">1.7.3 Overall confidence argument</h3>
          <div class="imagecontainer border" id="sid5866579837810795207">
            <div class="imageWithBorder">
              <img src="../img/SafetyPatternsCatalogue_The_Overall_Confidence_Argument.png" />
            </div>
            <div class="imagecaption">
              <p class="caption">
                <b>Figure
                1.7.3-A</b><a href="http://127.0.0.1:63320/node?ref=r%3Af484f3cb-b75d-4857-b03a-36f42bd7a5b9%28_100_Patterns%29%2F5728310034091203040" class="originalNode" title="open in MPS"></a>
              </p>
            </div>
          </div>
          <p class="body">
            <b>Problem and Solution</b>&nbsp;&nbsp;<br/>
Arguments that do not distinguish between the arguments of safety and confidence might lead to:<br/>
- voluminous, rambling, ad infinitum arguments;<br/>
- poorly documented safety argument and the confidence argument, because the lack of distinction between the two makes it more difficult to spot incompleteness or poor structure in either;<br/>
- necessary elements of the argument being sometimes omitted, because the need for the specific elements is lost in the volume of the argument;<br/>
- arguments becoming indirect and unfocused, and the link between elements of the argument and risk is often lost;<br/>
- unnecessary material bein sometimes included in arguments without proper con- sideration or explanation of its relevance – ‘just in case’;<br/>
- arguments becoming difficult to build, and weaknesses of the argument are sometimes not evident and so are easily overlooked;<br/>
- arguments becoming difficult to review because of the size and lack of focus;<br/>
Separation of the safety and confidence arguments offers the opportunity to<br/>
mitigate these difficulties by providing different foci for safety and confidence. In addition, careful attention to linking the two arguments provides a mechanism for guiding analysis of the interrelationship between safety and confidence;<br/>
<br/>
To gain assurance in the argumentation, the sub-claims put forward to implement the chosen argument strategy need to be, if true, a sufficient basis upon which to infer the conclusion stated in the parent claim.<br/>
It is necessary to provide a confidence argument that demonstrates why the asserted in- ference should be believed. The ACP for an asserted inference is the link between the parent claim and its strategy or sub-claims.
          </p>
          <p class="body">
            <b>Context</b>&nbsp;&nbsp;The individual fragments of a confidence argument, each addressing a particular assurance claim point in the safety argument, should be assembled together to form a single overall confidence argument (to accompny the single safety argument). To be truly comprehensive in the construction of this overall confidence argument would require that all of the assertions of the safety argument have an accompanying confidence (sub-)argument. This is illustrated in the three legs of the argument shown in this argumentation (arguing confidence for all inferences, all context and all evidence used in the safety argument).
          </p>
          <p class="body">
            <b>Implementation</b>&nbsp;&nbsp;In addition to the simple structure of the argument, there are a number of potentially important concerns at the level of the overall confidence argument. <br/>
Firstly, arguing the sufficiency of the overall confidence in the safety argument can be more complex than the simple composition of arguments of sufficient confidence for each argument assertion (in the same way that arguing the acceptability of overall risk is more complex than simply arguing the acceptability of the risk posed by each individual hazard). For example, an assurance deficit for one argument assertion may be justified as acceptable when considered in the context of other arguments and evidence in the safety case. Such a justification of how shortfalls in one part of the safety argument are compensated by other arguments and evidence needs to be addressed at the level of the overall confidence argument. Secondly, it is useful to examine and justify whether the multiple lines of argument offered up in the safety argument (undesirably) share common underlying assurance deficits (i.e. there are common modes of failure in the argument). Thirdly, for large safety arguments it may simply not be practical to provide arguments of confidence for every assertion in the safety argument. Instead, some selection and prioritisation of the assertions of the safety arguments to be covered by the confidence argument may need to be performed. This prioritisation would be done most appropriately by addressing those assertions relating to the most significant arguments of risk reduction in the primary safety argument. Obviously, care must be taken when making any decisions regarding parts of the confidence argument to omit.
          </p>
          <p class="body">
            <b>Related patterns &amp; Known Uses</b>&nbsp;&nbsp;More information about this pattern in:<br/>
- Hawkins R., Kelly T., Knight J., Graydon P. (2011) A New Approach to creating Clear Safety Arguments. In: Dale C., Anderson T. (eds) Advances in Systems Safety. Springer, London. https://doi.org/10.1007/978-0-85729-133-2_1
          </p>
          <p class="body">
            <strong class="bold">Note</strong>: Documentation provided from the following publication:<br/>
Hawkins R., Kelly T., Knight J., Graydon P. (2011) A New Approach to creating Clear Safety Arguments. In: Dale C., Anderson T. (eds) Advances in Systems Safety. Springer, London. https://doi.org/10.1007/978-0-85729-133-2_1
          </p>
        </div>
      </div>
      <div>
        <h2 id="sid1173803721179809901" class="section">1.8 Automotive-Specific Argument Patterns</h2>
        <div>
          <h3 id="sid2186533634773578105" class="section">1.8.1 High Level Vehicle Argument Pattern</h3>
          <div class="imagecontainer border" id="sid5866579837810795322">
            <div class="imageWithBorder">
              <img src="../img/SafetyPatternsCatalogue_High_Level_Vehicle_Safety_Argument_Pattern.png" />
            </div>
            <div class="imagecaption">
              <p class="caption">
                <b>Figure
                1.8.1-A</b><a href="http://127.0.0.1:63320/node?ref=r%3Af484f3cb-b75d-4857-b03a-36f42bd7a5b9%28_100_Patterns%29%2F6372820294458906141" class="originalNode" title="open in MPS"></a>
              </p>
            </div>
          </div>
          <p class="body">
            <b>Problem and Solution</b>&nbsp;&nbsp;Problem: The automotive industry has never been required to produce a safety case. Instead, it has relied on compliance with extensive regional and national regulation. With the imminent introduction of the automotive safety standard ISO 26262, the production of a safety case is now explicitly required by the standard for electrical and electronic systems. This presents both opportunities and challenges to safety practitioners and researchers within that industry. <br/>
Solution: The High Level Vehicle Argument Pattern concerns the overall safety of a vehicle and is the top-level goal of an Argument Pattern Catalogue for the automotive industry.
          </p>
          <p class="body">
            <b>Context</b>&nbsp;&nbsp;Pattern is used in the context of the automotive industry, in order to look at the issues of what a safety case might look like for a complete vehicle and how the ISO 26262 fits into the existing framework of automotive safety.<br/>
The top-level claim, ‘The vehicle is acceptable safety’, is made in the context of a definition of the vehicle (e.g. private passenger vehicle or commercial vehicle), a definition of the vehicle attributes (e.g. 0-60 time) and a physical representation of the vehicle.
          </p>
          <p class="body">
            <b>Participants &amp; Collaborations</b>&nbsp;&nbsp;The two high level strategies,
            Strategy Product Development
            and 
            Strategy Post Product Development
            , developed to support the top-level claim are based on the stage of the product within the product lifecycle, namely during and after product development. Four different Away Goals support these strategies. An Away Goal is a goal reference which is used to support, or provide contextual backing for, an argument presented in one argument module. However, the argument supporting that goal is presented in another argument module (hence creating interdependencies between argument modules). The Away Goal used are:<br/>
-
            Goal Pre-defined Safety Requirements
            : The vehicle satisfies predefined safety requirements, i.e. it has been homologated against regulations which capture essential vehicle attributes (e.g. braking system and steering system). The argument supporting the goals are represented as patterns from an Architecture Argument Pattern catalogue (referenced at the end of this document) and is explained in
            GSN Document Predefined_Safety_Requirements_Argument_Pattern
            ;<br/>
-
            Goal System Safety
            : A vehicle system is acceptably safe to operate in the specified environment; The argument supporting the goals are represented as patterns from an Architecture Argument Pattern catalogue (referenced at the end of this document) and is explained in 
            GSN Document Risk_Management_Argument_Pattern
            <br/>
-
            Goal Production Errors
            : The vehicle was free from known safety related defects when it was built. The argument supporting the goals are represented as patterns from an Architecture Argument Pattern catalogue (referenced at the end of this document);<br/>
-
            Goal Through Life Safety
            : The vehicle is subject to in-use monitoring, service updates and prescribed in-use maintenance. That is, the OEM has a dealer network capable of maintaining the vehicles correctly and has processes in place for evaluating and responding to field accidents or incidents. The argument supporting the goals are represented as patterns from an Architecture Argument Pattern catalogue (referenced at the end of this document)
          </p>
          <p class="body">
            <b>Related patterns &amp; Known uses</b>&nbsp;&nbsp;The pattern presented here is part of an Architecture Argument Pattern Catalogue for the automotive domain. All the information provided here is found in the following publication:<br/>
Robert Palin and Ibrahim Habli. 2010. Assurance of automotive safety - a safety case approach. In Proceedings of the 29th international conference on Computer safety, reliability, and security (SAFECOMP&apos;10). Springer-Verlag, Berlin, Heidelberg, 82–96.
          </p>
        </div>
        <div>
          <h3 id="sid2186533634773586251" class="section">1.8.2 Predefined Safety Requirements Argument Pattern</h3>
          <div class="imagecontainer border" id="sid5866579837810795449">
            <div class="imageWithBorder">
              <img src="../img/SafetyPatternsCatalogue_Predefined_Safety_Requirements_Argument_Pattern.png" />
            </div>
            <div class="imagecaption">
              <p class="caption">
                <b>Figure
                1.8.2-A</b><a href="http://127.0.0.1:63320/node?ref=r%3Af484f3cb-b75d-4857-b03a-36f42bd7a5b9%28_100_Patterns%29%2F2186533634773578311" class="originalNode" title="open in MPS"></a>
              </p>
            </div>
          </div>
          <p class="body">
            <b>Problem and Solution</b>&nbsp;&nbsp;Problem: The automotive industry has never been required to produce a safety case. Instead, it has relied on compliance with extensive regional and national regulation. With the imminent introduction of the automotive safety standard ISO 26262, the production of a safety case is now explicitly required by the standard for electrical and electronic systems. This presents both opportunities and challenges to safety practitioners and researchers within that industry. <br/>
Solution: The Predefined Safety Requirements Argument Pattern is part of an Argument Pattern Catalogue for the automotive industry. There are different types of automotive safety requirements. One type are the predefined safety requirements (1) which include the statutory regulations that must be met as a bare minimum in order to sell cars in the first instance. The Predefined Safety Argument Pattern is a reusable structure that provides guidance on how to address the safety requirements of cars.
          </p>
          <p class="body">
            <b>Context</b>&nbsp;&nbsp;Pattern is used in the context of the automotive industry, in order to look at the issues of what a safety case might look like for a complete vehicle and how the ISO 26262 fits into the existing framework of automotive safety.<br/>
The pre-defined safety requirements are mainly based on applicable regulations. Regulations, whether international or regional, are an agreed way of assessing vehicle systems.
          </p>
          <p class="body">
            <b>Participants &amp; collaborations</b>&nbsp;&nbsp;It would seem appropriate to group the various regulations and vehicle assessment tests according to the initiatives in use within the bigger picture of road safety as defined by the Haddon matrix, mentioned in 
            Justification Haddon Matrix
            . In the argument, three main claims are made concerning the pre-crash (
            Goal Pre-Crash
            ), crashworthiness (
            Goal Crashworthiness
            ) and post-crash (
            Goal Post-crash
            ) attributes of the vehicle, which need to be developed and instantiated. It is important to note that the evidence is used in the context of an Away Goal 
            Goal Homologation
            . This Away Goal refers to an argument which justifies that the evidence is independently verified and traceable. This is normally called a process-based argument or backing argument, which aims at justifying the process by which the evidence used in the primary product-based argument is generated (e.g. justifying the thoroughness of the review, quality of the review methods and competency and independence of the reviewers). Process-based arguments play a key role in justifying the trustworthiness of the evidence (i.e. addressing the simple question: why should anyone trust the evidence?).
          </p>
          <p class="body">
            <b>Related patterns &amp; Known uses</b>&nbsp;&nbsp;The pattern presented here is part of an Architecture Argument Pattern Catalogue for the automotive domain. All the information provided here is found in the following publication:<br/>
Robert Palin and Ibrahim Habli. 2010. Assurance of automotive safety - a safety case approach. In Proceedings of the 29th international conference on Computer safety, reliability, and security (SAFECOMP&apos;10). Springer-Verlag, Berlin, Heidelberg, 82–96.
          </p>
        </div>
        <div>
          <h3 id="sid2186533634773586357" class="section">1.8.3 Risk Management Argument Pattern</h3>
          <div class="imagecontainer border" id="sid5866579837810795562">
            <div class="imageWithBorder">
              <img src="../img/SafetyPatternsCatalogue_Risk_Management_Argument_Pattern.png" />
            </div>
            <div class="imagecaption">
              <p class="caption">
                <b>Figure
                1.8.3-A</b><a href="http://127.0.0.1:63320/node?ref=r%3Af484f3cb-b75d-4857-b03a-36f42bd7a5b9%28_100_Patterns%29%2F7220479442676509406" class="originalNode" title="open in MPS"></a>
              </p>
            </div>
          </div>
          <p class="body">
            <b>Problem and Solution</b>&nbsp;&nbsp;Problem: The automotive industry has never been required to produce a safety case. Instead, it has relied on compliance with extensive regional and national regulation. With the imminent introduction of the automotive safety standard ISO 26262, the production of a safety case is now explicitly required by the standard for electrical and electronic systems. This presents both opportunities and challenges to safety practitioners and researchers within that industry. <br/>
Solution: The Risk Management Argument Pattern is part of an Argument Pattern Catalogue for the automotive industry. This argument is one of the most important patterns described in the catalogue as it explicitly addresses the hazards and risks posed by a vehicle system. The argument supports the claim that a vehicle system is acceptably safe by justifying that the residual risks associated with the identified hazards have been reduced to an acceptable level. 
          </p>
          <p class="body">
            <b>Context</b>&nbsp;&nbsp;Pattern is used in the context of the automotive industry, in order to look at the issues of what a safety case might look like for a complete vehicle and how the ISO 26262 fits into the existing framework of automotive safety. The argument supports the claim that a vehicle system is acceptably safe by justifying that the residual risks associated with the identified hazards have been reduced to an acceptable level. 
          </p>
          <p class="body">
            <b>Participants &amp; collaborations</b>&nbsp;&nbsp;The argument that the residual risks associated with the identified hazards have been reduced to an acceptable level is split into two parts, addressing both the physical ( 
            Goal Physical safety
            ) and functional safety attributes ( 
            Goal Functional Safety
            ) of the system. In particular, the claims concerning the hazards related to the functional safety attributes are supported by the definition of safety goals which address these hazards. Finally, this argument addresses the claims concerning the safety goals by considering how the risks of the hazards have been managed by means of elimination, mitigation or mininisation. <br/>
Finally, within this argument pattern, there are three Away Goals, which refer to process-based arguments. The @goal Away Goal refers to an<br/>
argument which justifies the process by which the hazards have been identified. The
            Goal System Safety
            , which is actually an Away Goal, refers to an argument which justifies the specification of the safety goals. The 
            Goal System Safety
            , whic is actually an Away Goal refers to an argument which justifies the FMEA process. These Away Goals are developed in separate argument patterns.
          </p>
          <p class="body">
            <b>Related patterns &amp; Known uses</b>&nbsp;&nbsp;The pattern presented here is part of an Architecture Argument Pattern Catalogue for the automotive domain. All the information provided here is found in the following publication, including an example of how the pattern can be instantiated:<br/>
Robert Palin and Ibrahim Habli. 2010. Assurance of automotive safety - a safety case approach. In Proceedings of the 29th international conference on Computer safety, reliability, and security (SAFECOMP&apos;10). Springer-Verlag, Berlin, Heidelberg, 82–96.
          </p>
        </div>
        <div>
          <h3 id="sid2186533634773586463" class="section">1.8.4 Risk Mitigation Argument Pattern</h3>
          <div class="imagecontainer border" id="sid5866579837810795670">
            <div class="imageWithBorder">
              <img src="../img/SafetyPatternsCatalogue_Risk_Mitigation_Argument_Pattern.png" />
            </div>
            <div class="imagecaption">
              <p class="caption">
                <b>Figure
                1.8.4-A</b><a href="http://127.0.0.1:63320/node?ref=r%3Af484f3cb-b75d-4857-b03a-36f42bd7a5b9%28_100_Patterns%29%2F7133230218483032694" class="originalNode" title="open in MPS"></a>
              </p>
            </div>
          </div>
          <p class="body">
            <b>Problem and Solution</b>&nbsp;&nbsp;Problem: The automotive industry has never been required to produce a safety case. Instead, it has relied on compliance with extensive regional and national regulation. With the imminent introduction of the automotive safety standard ISO 26262, the production of a safety case is now explicitly required by the standard for electrical and electronic systems. This presents both opportunities and challenges to safety practitioners and researchers within that industry. <br/>
Solution: The Risk Mitigation Argument Pattern is part of an Argument Pattern Catalogue for the automotive industry. In the pattern documented in 
            GSN Document Risk_Management_Argument_Pattern
            , risk mitigation was considered as a means for managing the risks of the hazards addressed by the safety goals. Now it is described an argument pattern which appeals to mitigation by means of failure detection and diagnostics (reliability) and system degradation (availability).
          </p>
          <p class="body">
            <b>Context</b>&nbsp;&nbsp;Pattern is used in the context of the automotive industry, in order to look at the issues of what a safety case might look like for a complete vehicle and how the ISO 26262 fits into the existing framework of automotive safety. 
          </p>
          <p class="body">
            <b>Participants &amp; collaborations</b>&nbsp;&nbsp;The structure of the pattern is based upon the ability to detect hazardous conditions and reconfigure the system to a justified safe state, referred to as ‘system degradation’ in the ISO 26262 terminology. It is important to note that the system degradation leg is optional. This is because alternative strategies such notifying the driver or writing emergency procedures might be more applicable. With regard to restrictive or preventative use, there is an assumption in the argument regarding the driver being able to maintain the safety of the vehicle when the system or the vehicle is in the degraded state.
          </p>
          <p class="body">
            <b>Related patterns &amp; Known uses</b>&nbsp;&nbsp;The pattern presented here is part of an Architecture Argument Pattern Catalogue for the automotive domain. All the information provided here is found in the following publication:<br/>
Robert Palin and Ibrahim Habli. 2010. Assurance of automotive safety - a safety case approach. In Proceedings of the 29th international conference on Computer safety, reliability, and security (SAFECOMP&apos;10). Springer-Verlag, Berlin, Heidelberg, 82–96.
          </p>
        </div>
      </div>
    </div>
  </body>
</html>